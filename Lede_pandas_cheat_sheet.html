<!doctype html>
<HTML lang="en">
<HEAD>
	<meta charset="utf-8" />
	<title>.</title>
	<link rel="shortcut icon" href="logo.ico">

	<link href='https://fonts.googleapis.com/css?family=Ubuntu+Mono' rel='stylesheet' type='text/css'>
	<link href='https://fonts.googleapis.com/css?family=Ubuntu:500,400' rel='stylesheet' type='text/css'>
	<link href='https://fonts.googleapis.com/css?family=Economica:400,700italic&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" media="all" href="index.css" />
	<style>
		.boxcontent{
			display:none;
		}
	</style>

	<!-- <script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>
	<script src="http://isotope.metafizzy.co/jquery.isotope.min.js"></script> -->
	<script src="lib/jquery-2.0.3.min.js"></script>
	<script src="lib/jquery.autoellipsis-1.0.10.min.js"></script>
	<script src="lib/underscore-min.1.5.0.js"></script>
	<script src="lib/backbone-min.1.1.2.js"></script>
	<script src="index.js"></script>
	<script>
	</script>
</HEAD>

<BODY>
	<div class="wrapper">
		<div id="menuarea">
		</div>
		<div id="screenarea">
			<div class="screen" id="screen_lede">
				<!-- boxcontent -->
					<div class="boxcontent box-code" id="code_installing_importing">
						<div class="boxtitle">
							<span class="boxtitle">INSTALLING &amp; IMPORTING PANDAS</span>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									Anaconda
								</div>
								<div class="codeinput">
									import pandas as pd
								</div>
								<div class="markdown">
									`as` is for when we want an ALIAS for our module. We're too lazy to type out "pandas" every time, so we're telling Python we're just going to type "pd" instead.
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									setting options
								</div>
								<div class="codeinput">
									pd.set_option( "max.columns",<span class="usermade">55</span> )
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									defining a function that checks if an object is NOT np.NaN (of which there will be many)
								</div>
								<div class="codeinput">
									from numpy import isnan
									<br/>notnan = lambda x: not ( isinstance( x,float ) and isnan( x ) )
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_from_other_data_structures">
						<div class="boxtitle">
							CREATING A DATAFRAME FROM OTHER DATA STRUCTURES
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="subchunktitle">
									Creating a dataframe from a LIST OF LISTS
								</div>
								<div class="markdown">
								</div>
								<div class="codeinput">
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="subchunktitle">
									Creating a dataframe from a LIST OF DICTIONARIES
								</div>
								<div class="markdown">
								</div>
								<div class="codeinput">
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="subchunktitle">
									Creating a dataframe from a DICTIONARY OF LISTS
								</div>
								<div class="markdown">
								</div>
								<div class="codeinput">
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="subchunktitle">
									Creating a dataframe from a NUMPY ARRAY
								</div>
								<div class="markdown">
								</div>
								<div class="codeinput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_reading_file">
						<div class="boxtitle">
							CREATING A DATAFRAME BY READING A FILE
						</div>

						<div class="chunk">
		 					<div class="subchunk">
								<div class="subchunktitle">
									Creating a dataframe by reading a file of VALUES SEPARATED BY COMMAS (CSV), TABS (TSV), WHITESPACE, OR OTHER CHARACTERS
								</div>
								<div class="markdown">
									We can read a file
									<br/>&bull; located <span class="usermade">in our computer</span> at <span class="usermade">"ourfile.csv"</span>
									<br/>&bull; containing data values as text separated by <span class="usermade">commas (",")</span>
									<br/>&bull; whose first line <span class="usermade">is</span> the column field names we want to use
									<br/>as a pandas dataframe.
									<br/>Here, we assign that value to a variable with the name <span class="extracode">ourdataframe</span>.
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/><span class="extracode">ourdataframe =</span> pd.read_csv( <span class="usermade">"ourfile.csv"</span> )
								</div>

								<div class="markdown">
									...a file online
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/>from urllib2 import Request,urlopen
									<br/><span class="extracode">ourdataframe =</span> pd.read_csv( urlopen( Request( <span class="usermade">"https://oursite.com/ourfile.csv"</span> ) ) )
								</div>

								<div class="markdown">
									...values are separated by <span class="usermade">tabs ("\t")</span>
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/><span class="extracode">ourdataframe =</span> pd.read_csv( <span class="usermade">"ourfile.csv"</span>,sep=<span class="usermade">"\t"</span> )
								</div>

								<div class="markdown">
									...values are separated by <span class="usermade">whitespace</span>
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/><span class="extracode">ourdataframe =</span> pd.read_csv( <span class="usermade">"ourfile.csv"</span>,delim_whitespace=True )
								</div>

								<div class="markdown">
									...the first row of the file is the header &amp; we give it a new header as a list of strings anyway
								</div>
								<div class="codeinput">
								</div>

								<div class="markdown">
									...the first row of the file is NOT the header &amp; we give it a new header as a list of strings
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/><span class="extracode">ourdataframe =</span> pd.read_csv( <span class="usermade">"ourfile.csv"</span>,header=None,names=<span class="usermade">[ "area","perimeter","compactness" ]</span> )
								</div>

								<div class="markdown">
									...encoding
								</div>
								<div class="codeinput">
								</div>

								<div class="markdown">
									...
								</div>
								<div class="codeinput">
									df = pd.read_csv( "ourfile.csv",parse_dates=True )
								</div>

								<div class="markdown">
									... with \n in entries
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/>import csv
									<br/>with open( <span class="usermade">"ourfile.csv"</span>,"rU" ) as <span class="temp">ourfile</span>:
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;<span class="extracode">ourdataframe =</span> pd.DataFrame( list( csv.DictReader( <span class="temp">ourfile</span> ) ) )
								</div>
							</div>
						</div>

						<div class="chunk">
		 					<div class="subchunk">
								<div class="subchunktitle">
									Creating a dataframe by reading a FIXED-WIDTH FILE
								</div>
							</div>
						</div>

		 				<div class="chunk">
		 					<div class="subchunk">
								<div class="subchunktitle">
									Creating a dataframe by reading a MICROSOFT EXCEL file
								</div>
								<div class="markdown">
									&bull; We can read the <span class="usermade">1</span>st sheet of an Excel file located at <span class="usermade">"ourfile.xlsx"</span> as a pandas dataframe.
									<br/>Here, we assign that value to a variable with the name <span class="extracode">ourdataframe</span>.
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/><span class="extracode">ourdataframe =</span> pd.read_excel( <span class="usermade">"ourfile.xlsx"</span> )
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/><span class="extracode">ourdataframe =</span> pd.ExcelFile( <span class="usermade">"ourfile.xlsx"</span> ).parse( <span class="usermade">0</span> )
								</div>
							</div>

		 					<div class="subchunk">
								<div class="markdown">
									&bull; We can read the sheet named <span class="usermade">"Sheet1"</span> of an Excel file located at <span class="usermade">"ourfile.xlsx"</span> as a pandas dataframe.
									<br/>Here, we assign that value to a variable with the name <span class="extracode">ourdataframe</span>.
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/><span class="extracode">ourdataframe =</span> pd.ExcelFile( <span class="usermade">"ourfile.xlsx"</span> ).parse( <span class="usermade">"Sheet1"</span> )
								</div>
								<div class="markdown">
									How do we know what names the sheets in our Excel file have? Like this:
								</div>
							</div>

		 					<div class="subchunk">
								<div class="subchunktitle">
									Checking the names of sheets in a microsoft excel file
								</div>
								<div class="markdown">
									&bull; We can read the names of all the sheets  of an Excel file located at <span class="usermade">"ourfile.xlsx"</span> as a list of strings.
									<br/>Here, we print that value out.
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/><span class="extracode">print</span> pd.ExcelFile( <span class="usermade">"ourfile.xlsx"</span> ).sheet_names
								</div>
								<div class="codeoutput">
									[u'Summary', u'Main', u'Appendix']
								</div>
							</div>
							
		 					<div class="subchunk">
								<div class="markdown">
									Putting it all together, we can create a dictionary of dataframes as values
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/><span class="temp">ourexcelfile</span> = pd.ExcelFile( <span class="usermade">"ourfile.xlsx"</span> )
									<br/><span class="extracode">ourdictionary =</span> { <span class="temp">s</span>:<span class="temp">ourexcelfile</span>.parse( <span class="temp">s</span> ) &nbsp;for <span class="temp">s</span> in <span class="temp">ourexcelfile</span>.sheet_names }
								</div>
		 					</div>
						</div>
					</div>

					<div class="boxcontent box-exam" id="exam_reading_seeds_file">
						<div class="boxtitle">
							?
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									from urllib2 import Request,urlopen
									<br/>ourdataframe = pd.read_csv( urlopen( Request( "https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt" ) ),delim_whitespace=True,header=None,names=[ "area","perimeter","compactness","length of kernel","width of kernel","asymmetry coefficient","length of kernel groove","variety of wheat" ] )
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_checking_basic_properties">
						<div class="boxtitle">
							CHECKING (AND CHANGING) A DATAFRAME&rsquo;S BASIC PROPERTIES
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="subchunktitle">
									Checking a dataframe&rsquo;s NUMBER OF ROWS &amp; NUMBER OF COLUMNS
								</div>
								<div class="markdown">
									&bull; as a tuple of length 2
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="usermade">ourdataframe</span>.shape
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="subchunktitle">
									Checking a dataframe&rsquo;s DATA TYPES by COLUMN
								</div>
								
								<div class="markdown">
									&bull; as a column (pandas series) # `dtype: float64` at the end of results # the datatype pandas uses to encode the data
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="usermade">ourdataframe</span>.dtypes
								</div>
								<div class="codeoutput">
								</div>
							</div>
								
							<div class="subchunk">
								<div class="subchunktitle">
									CHANGING a dataframe&rsquo;s DATA TYPES by COLUMN
								</div>

								<div class="markdown">
									&bull; We can change
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span>[<span class="usermade">"ourcolumnname"</span>] = <span class="usermade">ourdataframe</span>[<span class="usermade">"ourcolumnname"</span>].astype( <span class="usermade">int</span> )
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span>[<span class="usermade">"ourcolumnname"</span>] = <span class="usermade">ourdataframe</span>[<span class="usermade">"ourcolumnname"</span>].convert_objects( convert_numeric=True )
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span>[<span class="usermade">"ourcolumnname"</span>] = <span class="usermade">ourdataframe</span>[<span class="usermade">"ourcolumnname"</span>].astype( <span class="usermade">str</span> )
								</div>
								<div class="codeinput">
									from numpy import isnan
									<br/>notnan = lambda x: not ( isinstance( x,float ) and isnan( x ) )
									<br/><span class="usermade">ourdataframe</span>[<span class="usermade">"ourcolumnname"</span>] = <span class="usermade">ourdataframe</span>[<span class="usermade">"ourcolumnname"</span>].apply( lambda x: <span class="usermade">str</span>( x ) if notnan( x ) &nbsp;else x )
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span> = <span class="usermade">ourdataframe</span>.astype( <span class="usermade">int</span> )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="subchunktitle">
									Checking a dataframe&rsquo;s ROW INDEX NAMES
								</div>
								<div class="markdown">
									&bull; as
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="usermade">ourdataframe</span>.index
								</div>
								<div class="markdown">
									as a &lt;type 'numpy.ndarray'&gt;
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="usermade">ourdataframe</span>.index.values
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="subchunktitle">
									CHANGING a dataframe&rsquo;s ROW INDEX NAMES
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="subchunktitle">
									Checking a dataframe&rsquo;s COLUMN NAMES
								</div>

								<div class="markdown">
									&bull; as a pandas index (behaves like a list)
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="usermade">ourdataframe</span>.columns
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									as a list
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> list( <span class="usermade">ourdataframe</span>.columns )
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="subchunktitle">
									CHANGING a dataframe&rsquo;s column names
								</div>

								<div class="markdown">
									&bull; We can change
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span>.columns = <span class="usermade">[ u'Gender',u'height',u'weight' ]</span>
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span> = <span class="usermade">ourdataframe</span>.rename( columns={ <span class="usermade">"old1"</span>:<span class="usermade">"new1"</span>,<span class="usermade">"old2"</span>:<span class="usermade">"new2"</span> } )
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									adding a prefix/suffix to (all) column names
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span> = <span class="usermade">ourdataframe</span>.add_prefix( <span class="usermade">"cumber_"</span> )
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span> = <span class="usermade">ourdataframe</span>.add_suffix( <span class="usermade">"_batch"</span> )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull; number of NOT missing values (NOT NaN) in each column
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span>.count()
								</div>
								<div class="codeoutput">
								</div>
								
								<div class="markdown">
									&bull; number of missing values (NaN) in each column
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span>.isnull().sum()
								</div>
								<div class="codeoutput">
								</div>
								
								<div class="markdown">
									&bull; proportion of missing values (NaN) in each column
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span>.isnull().sum() / <span class="usermade">ourdataframe</span>.shape[0]
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									df = df.fillna( 0 )
								</div>
								<div class="codeinput">
									df = df.dropna()
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull; unique values of a column
								</div>
								<div class="codeinput">
									df["high_quality"].unique()
								</div>
								<div class="codeoutput">
									array([ 0.,  1.])
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull;  values of a column
								</div>
								<div class="codeinput">
									df["high_quality"].values
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									replace all entries "old" with "new"
								</div>
								<div class="codeinput">
									df = df.replace( "old","new" )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_selecting_by_position_or_name">
						<div class="boxtitle">
							SELECTING ROWS &amp; COLUMNS BY POSITION OR NAME
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull; We can select rows in the <span class="usermade">first/last</span> <span class="usermade">5</span> row index position
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="usermade">ourdataframe</span>.head()
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="usermade">ourdataframe</span>.tail()
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull; We can select rows by row index positions from 3000 to (NOT including) 3005
								</div>
								<div class="codeinput">
									print df[3000:3005]
								</div>
								<div class="codeinput">
									print df[3000:3005:2]
								</div>
								<div class="markdown">
									`print df[3000]` gives you an error # high-level software like pandas: makes assumptions , messes up
								</div>

								<div class="codeinput">
									print df.iloc[3000:3005]
								</div>
								<div class="codeinput">
									print df.iloc[3000:3005:2]
								</div>
								<div class="codeinput">
									print df.iloc[3000]
								</div>

								<div class="codeoutput">
								</div>
								<div class="codeoutput">
								</div>
								<div class="codeoutput">
								</div>
								<div class="markdown">
									# like a sql operation `SELECT course_id FROM df OFFSET 3000 LIMIT 5
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull; We can select rows by row index names from 3000 to (including) 3005
								</div>

								<div class="codeinput">
									print df.ix[3000:3005]
								</div>
								<div class="codeinput">
									print df.ix[3000:3005:2]
								</div>
								<div class="codeinput">
									print df.ix[3000]
								</div>
								
								<div class="codeinput">
									print df.loc[3000:3005]
								</div>
								<div class="codeinput">
									print df.loc[3000:3005:2]
								</div>
								<div class="codeinput">
									print df.loc[3000]
								</div>

								<div class="codeoutput">
								</div>
								<div class="codeoutput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull; We can select columns by column positions
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span>[<span class="usermade">[1]</span>]
								</div>
								<div class="codeinput">
									print df.ix[ :,<span class="usermade">[1]</span> ]
								</div>
								<div class="codeinput">
									print df.ix[ :,<span class="usermade">2:5</span> ]
								</div>
								<div class="codeoutput">
								</div>
								<div class="markdown">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull; We can select 1 column by column name
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span>[<span class="usermade">"ourcolumnname"</span>]
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span>.<span class="usermade">ourcolumnname</span>
								</div>
								<div class="codeoutput">
								</div>
								<div class="markdown">
									# like a sql operation `SELECT ourcolumnname FROM ourdataframe`
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull; We can select columns by column names
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span>[<span class="usermade">[ <span class="usermade">ourcolumnname1</span>,<span class="usermade">ourcolumnname2</span>,<span class="usermade">ourcolumnname3</span> ]</span>]
								</div>
								<div class="codeoutput">
								</div>
								<div class="markdown">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_selecting_by_condition">
						<div class="boxtitle">
							SELECTING ROWS THAT MEET CONDITIONS
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
								<div class="markdown">
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
								<div class="markdown">
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
								<div class="markdown">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_vectorization">
						<div class="boxtitle">
							VECTORIZATION
						</div>
						<div class="markdown">
							Use vectorization to engineer our features for natural language classification and clustering problems, rather than explicitly defining our features by hand.
							<br/>Turn text into data that computer can understand, a matrix
							<br/>Turn each word into a feature best described as "The number of times that word appears in this document".
							
							<br/>
							<br/>Vectorizing text is a fundamental concept in applying both supervised and unsupervised learning to documents.

							<br/>
							<br/># BAG-OF-WORDS MODEL # works reasonably well
							<br/># Michael: are there more sophisticated methods? # of course # CONDITIONAL RANDOM FIELDS
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									<span class="usermade">ourdocs</span> can be a list of strings, a numpy array of strings, or a pandas column (series) of strings
									<br/>raw counts
								</div>
								<div class="codeinput">
									<span class="extracode">
										<span class="usermade">ourdocs</span> = [
										<br/>&nbsp;&nbsp;&nbsp;&nbsp;"An act to amend Section 44277 of the Education Code, relating to teachers.",
										<br/>&nbsp;&nbsp;&nbsp;&nbsp;"An act relative to health care coverage",
										<br/>]
									</span>
									<br/>from sklearn.feature_extraction.text import CountVectorizer
									<br/><span class="temp">ourvectorizer</span> = CountVectorizer()
									<br/><span class="temp">ourdoctermmatrix</span> = <span class="temp">ourvectorizer</span>.fit_transform( <span class="usermade">ourdocs</span> ).toarray() # &lt;type 'numpy.ndarray'&gt;
									<br/><span class="temp">ourterms&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span> = <span class="temp">ourvectorizer</span>.get_feature_names()
								</div>

								<div class="markdown">
								</div>
								<div class="codeinput">
									<span class="temp">ourdoctermmatrix</span>
								</div>
								<div class="codeoutput">
									<span class="pre">array([[1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2],</span>
									<br/><span class="pre">       [0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1]])</span>
								</div>

								<div class="markdown">
								</div>
								<div class="codeinput">
									<span class="temp">ourterms</span>
								</div>
								<div class="codeoutput">
									[u'44277', u'act', u'amend', u'an', u'care', u'code', u'coverage', u'education', u'health', u'of', u'relating', u'relative', u'section', u'teachers', u'the', u'to']
								</div>

								<div class="markdown">
								</div>
								<div class="codeinput">
									pd.DataFrame( <span class="temp">ourdoctermmatrix</span>,index=<span class="usermade">ourdocs</span>,columns=<span class="temp">ourterms</span> )
								</div>
								<div class="codeinput">
									pd.DataFrame( <span class="temp">ourdoctermmatrix</span>,index=[ ( d[:12]+"..." if 15 &lt; len( d ) &nbsp; else d ) &nbsp;for d in <span class="usermade">ourdocs</span> ],columns=<span class="temp">ourterms</span> )
								</div>
								<div class="codeoutput">
									<span class="pre">                 44277  act  amend  an  care  code  coverage  education  \</span>
									<br/><span class="pre">An act to am...      1    1      1   1     0     1         0          1   </span>
									<br/><span class="pre">An act relat...      0    1      0   1     1     0         1          0   </span>
									<br/>
									<br/><span class="pre">                 health  of  relating  relative  section  teachers  the  to  </span>
									<br/><span class="pre">An act to am...       0   1         1         0        1         1    1   2  </span>
									<br/><span class="pre">An act relat...       1   0         0         1        0         0    0   1 </span>
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									other vectorizers: TF, normalized for document length, raw count vectors normalized to unit vectors
								</div>
								<div class="codeinput">
									from sklearn.feature_extraction.text import TfidfVectorizer
									<br/><span class="temp">ourvectorizer</span> = TfidfVectorizer( use_idf=False )
								</div>
								<div class="markdown">
									other vectorizers: TFIDF, sklearn variant (<a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html">tf * (idf + 1), instead of tf * idf</a>)
								</div>
								<div class="codeinput">
									from sklearn.feature_extraction.text import TfidfVectorizer
									<br/><span class="temp">ourvectorizer</span> = TfidfVectorizer()
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									tweaking the features:
								</div>

								<div class="markdown">
									# relative large FEATURE SPACE -- not good, remove STOP WORDs to reduce the feature space
									<br/># Arthur: What about Italian or German? # English is the only language currently supported in the TFIDF vectorizer: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html # At least they have it written so the language could change.
									<br/># NLTK supports 11 languages: https://github.com/nltk/nltk/blob/886abfd5faeaf8c549f89426f13a97ed3c138ca3/nltk/corpus/europarl_raw.py
								</div>
								<div class="codeinput">
									<span class="temp">ourvectorizer</span> = CountVectorizer( stop_words='english' )
								</div>
								<div class="markdown">
									We can define our own stop words
								</div>
								<div class="codeinput">
									<span class="temp">ourvectorizer</span> = CountVectorizer( stop_words=[ 'mr','congress','chairman','madam','amendment','legislation','speaker' ] )
								</div>
								<div class="codeinput">
									import nltk
									<br/># nltk.download() # download nltk.corpus.stopwords
									<br/>ourstopwords = nltk.corpus.stopwords.words( 'english' ) + [ 'mr','congress','chairman','madam','amendment','legislation','speaker' ]
									<br/><span class="temp">ourvectorizer</span> = CountVectorizer( stop_words=ourstopwords )
								</div>

								<div class="markdown">
									# remove words that only appear in a small number of documents
								</div>
								<div class="codeinput">
									<span class="temp">ourvectorizer</span> = CountVectorizer( min_df=2 )
								</div>

								<div class="markdown">
									# remove words that appear in a large number of documents
								</div>
								<div class="codeinput">
									<span class="temp">ourvectorizer</span> = CountVectorizer( max_df=7 )
								</div>

								<div class="markdown">
									# create a feature vector of all 1-grams and 2-grams
									<br/># N-GRAM: a sequence of N words
									<br/># Notice that `u'44277 education'` is from "44277 of the Education" with the stop words "of" "the" gone # Spe: Are weird N-grams like this actually useful?
								</div>
								<div class="codeinput">
									<span class="temp">ourvectorizer</span> = CountVectorizer( ngram_range=( 1,2 ) )
								</div>
								<div class="markdown">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									<span class="extracode">ourdoctermmatrix</span> doesn't have to be a numpy array
								</div>
								<div class="codeinput">
									<span class="extracode">ourdoctermmatrix =</span> <span class="temp">ourvectorizer</span>.fit_transform( <span class="usermade">ourdocs</span> ).todense() # &lt;class 'numpy.matrixlib.defmatrix.matrix'&gt;
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									...new documents, old terms
								</div>
								<div class="codeinput">
									<span class="extracode">
										<span class="usermade">newdocs</span> = [
										<br/>&nbsp;&nbsp;&nbsp;&nbsp;"Public postsecondary education: executive officer compensation.",
										<br/>&nbsp;&nbsp;&nbsp;&nbsp;"An act to add Section 236.3 to the Education code, related to the pricing of college textbooks.",
										<br/>&nbsp;&nbsp;&nbsp;&nbsp;"Political Reform Act of 1974: campaign disclosures.",
										<br/>&nbsp;&nbsp;&nbsp;&nbsp;"An act to add Section 236.3 to the Penal Code, relating to human trafficking.",
										<br/>]
									</span>
									<br/><span class="extracode">newdoctermmatrix =</span> <span class="temp">ourvectorizer</span>.transform( <span class="usermade">newdocs</span> ).toarray()
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull; in our examples, 
								</div>
								<div class="codeinput">
									from sklearn.feature_extraction.text import CountVectorizer
									<br/><span class="temp">ourvectorizer</span> = CountVectorizer()
									<br/><span class="temp">train_x</span> = <span class="temp">ourvectorizer</span>.fit_transform( <span class="usermade">train["text"]</span> ).toarray()
								</div>
								<div class="codeinput">
									from sklearn.feature_extraction.text import TfidfVectorizer 
									<br/><span class="temp">ourvectorizer</span> = TfidfVectorizer( use_idf=False ) 
									<br/><span class="temp">train_x</span> = <span class="temp">ourvectorizer</span>.fit_transform( <span class="usermade">train["text"]</span> ).toarray()
								</div>
								<div class="codeinput">
									from sklearn.feature_extraction.text import TfidfVectorizer 
									<br/><span class="temp">ourvectorizer</span> = TfidfVectorizer() 
									<br/><span class="temp">train_x</span> = <span class="temp">ourvectorizer</span>.fit_transform( <span class="usermade">train["text"]</span> ).toarray()
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
									<span class="temp">test_x</span> = <span class="temp">ourvectorizer</span>.transform( <span class="usermade">test["text"]</span> )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_sentence_segmentation">
						<div class="boxtitle">
							sentence segmentation
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									from nltk.tokenize import sent_tokenize
									<br/>sent_tokenize( <span class="usermade">ourstring</span> )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_removing_punctuation_from_string">
						<div class="boxtitle">
							removing punctuation from a string
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									import re,string
									<br/>ourpunctuations = re.compile( '[%s]' % re.escape( string.punctuation ) )
									<br/>ourpunctuations.sub( "",<span class="usermade">"To-morrow, and to-morrow, and to-morrow,"</span> )
								</div>
								<div class="markdown">
									`re.escape()` returns string with all non-alphanumerics backslashed; this is useful if you want to match an arbitrary literal string that may have regular expression metacharacters in it.
								</div>
								<div class="codeinput">
									re.sub( '[%s]' % re.escape( string.punctuation ),"",<span class="usermade">"To-morrow, and to-morrow, and to-morrow,"</span> )
								</div>
								<div class="codeinput">
									re.sub( '[%s]' % string.punctuation,"",<span class="usermade">"To-morrow, and to-morrow, and to-morrow,"</span> )
								</div>
								<div class="codeinput">
									re.sub( "["+string.punctuation+"]","",<span class="usermade">"To-morrow, and to-morrow, and to-morrow,"</span> )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									import string
									<br/>string.punctuation
								</div>
								<div class="codeoutput">
									'!"#$%&amp;\'()*+,-./:;&lt;=>?@[\\]^_`{|}~'
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									import string
									<br/>set( string.punctuation )
								</div>
								<div class="codeoutput">
									set(['!', '#', '"', '%', '$', "'", '&amp;', ')', '(', '+', '*', '-', ',', '/', '.', ';', ':', '=', '&lt;', '?', '>', '@', '[', ']', '\\', '_', '^', '`', '{', '}', '|', '~'])
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									import re,string
									<br/>re.escape( string.punctuation )
								</div>
								<div class="codeoutput">
									'\\!\\"\\#\\$\\%\\&amp;\\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\&lt;\\=\\>\\?\\@\\[\\\\\\]\\^\\_\\`\\{\\|\\}\\~'
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									import re,string
									<br/>'[%s]' % re.escape( string.punctuation )
								</div>
								<div class="codeoutput">
									'[\\!\\"\\#\\$\\%\\&amp;\\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\&lt;\\=\\>\\?\\@\\[\\\\\\]\\^\\_\\`\\{\\|\\}\\~]'
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									import re,string
									<br/>re.compile( '[%s]' % re.escape( string.punctuation ) )
								</div>
								<div class="codeoutput">
									&lt;_sre.SRE_Pattern object at 0x1002c8cb0>
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_cross_validation">
						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="markdown">
									cross validation # np.array
									<br/># http://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics
									<br/>'accuracy' (default), 'adjusted_rand_score', 'average_precision', 'f1', 'log_loss', 'mean_absolute_error', 'mean_squared_error', 'precision', 'r2', 'recall', 'roc_auc'
									<br/># http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter
								</div>
								<div class="codeinput">
									<span class="extracode">
										from sklearn import datasets
										<br/>ourdataset = datasets.load_iris()
									</span>
									<br/>from sklearn.tree import DecisionTreeClassifier
									<br/>from sklearn.cross_validation import cross_val_score
									<br/><span class="extracode">ourscores =</span> cross_val_score( DecisionTreeClassifier(),<span class="usermade">ourdataset.data</span>,<span class="usermade">ourdataset.target</span>,cv=<span class="usermade">10</span>,scoring=<span class="usermade">"f1"</span> )
								</div>
								<div class="codeoutput">
									<span class="pre">array([ 1.        ,  0.93265993,  1.        ,  0.93265993,  0.93265993,</span>
									<br/><span class="pre">        0.86666667,  0.93265993,  0.93265993,  1.        ,  1.        ])</span>
								</div>

								<div class="markdown">
									a more elaborated way of creating the cross-folds. cross_val_score is already doing this under the hood. We're just making it explicit
								</div>
								<div class="codeinput">
									<span class="extracode">
										from sklearn import datasets
										<br/>ourdataset = datasets.load_iris()
									</span>
									<br/>from sklearn.tree import DecisionTreeClassifier
									<br/>from sklearn.cross_validation import KFold,cross_val_score
									<br/><span class="temp">ourkfold</span> = KFold( len( <span class="usermade">ourdataset.data</span> ),10,shuffle=True,random_state=0 )
									<br/><span class="extracode">ourscores =</span> cross_val_score( DecisionTreeClassifier(),<span class="usermade">ourdataset.data</span>,<span class="usermade">ourdataset.target</span>,cv=<span class="temp">ourkfold</span>,scoring=<span class="usermade">"f1"</span> )
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull; ...we can try looking at
								</div>
								<div class="codeinput">
									ourscores.mean()
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_hold_out">
						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull; train_x,test_x,train_y,test_y
									<br/>can specify `test_size=0.25` too
								</div>
								<div class="codeinput">
									from sklearn.cross_validation import train_test_split
									<br/>train_x,test_x,train_y,test_y = train_test_split( df[ [ 'density','sulphates','residual_sugar' ] ],df['high_quality'],train_size=0.75 )
								</div>
								<div class="codeinput">
								</div>

								<div class="markdown">
									&bull; train,test
									<br/># Some people get numpy arrays, some people get dataframes
								</div>
								<div class="codeinput">
									from sklearn.cross_validation import train_test_split
									<br/>train,test = train_test_split( df[ [ 'density','sulphates','residual_sugar','high_quality' ] ],train_size=0.75 )
								</div>
								<div class="codeinput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-defi" id="defi_scoring_stuff">
						<div class="boxtitle">
							...
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									<span class="pre">number of   <span class="posi">true positive</span>s  +  number of <span class="posi">false</span> <span class="nega">negative</span></span>s  +
									<br/><span class="pre">  (classified as <span class="posi">positive</span>,         (classified as <span class="nega">negative</span></span>,
									<br/><span class="pre">            actually <span class="posi">positive</span>)                   actually <span class="posi">positive</span></span>)
									<br/>
									<br/><span class="pre">number of <span class="nega">false</span> <span class="posi">positive</span>s  + number of   <span class="nega">true negative</span></span>s
									<br/><span class="pre">  (classified as <span class="posi">positive</span>,         (classified as <span class="nega">negative</span></span>,
									<br/><span class="pre">            actually <span class="nega">negative</span>)                   actually <span class="nega">negative</span></span>)
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-defi" id="defi_regression">
						<div class="boxtitle">
							REGRESSION
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									"This of course comes with a huge, blinking-red caveat: This is an algorithms class, and we're not getting deep enough into the guts of statistical regression for you to run out and write full-on stories based on your findings. There are things like p-values to consider, as well as rules of thumb for interpreting r-squared. If you'd like to get more in depth with that, we can carve out some time later in the course." -Chase Davis
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_linear_regression">
						<div class="boxtitle">
							LINEAR REGRESSION
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
									<br/>In its simplest form, 
									<br/><span class="usermade">train_x</span>
									<br/><span class="usermade">train_y</span>
								</div>
								<div class="codeinput">
									<span class="extracode">
										import pandas as pd
										<br/>ourdataframe = pd.read_csv( "ontime_reports_may_2015_ny.csv" )[ [ "LATE_AIRCRAFT_DELAY","CARRIER_DELAY","DEP_DELAY" ] ].dropna()
										<br/>train_x = ourdataframe[ [ "LATE_AIRCRAFT_DELAY","CARRIER_DELAY" ] ]
										<br/>train_y = ourdataframe["DEP_DELAY"]
									</span>
									<br/>from sklearn.linear_model import LinearRegression
									<br/><span class="temp">ourmodel</span> = LinearRegression().fit( <span class="usermade">train_x</span>,<span class="usermade">train_y</span> )
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull;
									<br/>we want to see the effect of <span class="usermade">"Height"</span> on <span class="usermade">"Weight"</span>
									<br/>We want <span class="usermade">"Weight"</span> in terms of <span class="usermade">"Height"</span>
									<br/># `sklearn` is a package for doing linear regression (there are others) # general purpose library
									<br/>Might have to do `ourdataframe = ourdataframe.dropna()` or `ourdataframe = ourdataframe.fillna( 0 )` to avoid `ValueError: Input contains NaN, infinity or a value too large for dtype('float64').`
									<br/># first we create a LinearRegression object #then fit the data to the values
									<br/>`ourmodel` has `&lt;class 'sklearn.linear_model.base.LinearRegression'&gt;`
									<br/>`print ourmodel` gives `LinearRegression(copy_X=True, fit_intercept=True, normalize=False)`
								</div>
								<div class="codeinput">
									<span class="extracode">
										import pandas as pd
										<br/>ourdataframe = pd.read_csv( "heights_weights_genders.csv" )
									</span>
									<br/>from sklearn.linear_model import LinearRegression
									<br/><span class="temp">ourmodel</span> = LinearRegression().fit( <span class="usermade">ourdataframe</span>[ [ <span class="usermade">"Height"</span> ] ],<span class="usermade">ourdataframe</span>[<span class="usermade">"Weight"</span>] )
								</div>
								<div class="codeinput">
									<span class="extracode">
										import pandas as pd
										<br/>ourdataframe = pd.read_csv( "ontime_reports_may_2015_ny.csv" )[ [ "LATE_AIRCRAFT_DELAY","CARRIER_DELAY","DEP_DELAY" ] ].dropna()
									</span>
									<br/>from sklearn.linear_model import LinearRegression
									<br/><span class="temp">ourmodel</span> = LinearRegression().fit( <span class="usermade">ourdataframe</span>[ [ <span class="usermade">"LATE_AIRCRAFT_DELAY"</span>,<span class="usermade">"CARRIER_DELAY"</span> ] ],<span class="usermade">ourdataframe</span>[<span class="usermade">"DEP_DELAY"</span>] )
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull; ...the R-squared (coefficient of determination)
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.score( <span class="usermade">ourdataframe</span>[ [ <span class="usermade">"Height"</span> ] ],<span class="usermade">ourdataframe</span>[<span class="usermade">"Weight"</span>] )
								</div>
								<div class="codeoutput">
									0.855174212061
								</div>

								<div class="markdown">
									&bull; ...the slope (m) of our regression line # one for each INdependent variable
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.coef_
								</div>
								<div class="codeoutput">
									array([ 7.71728764])
								</div>

								<div class="markdown">
									&bull; ...the y-intercept (b) (value when INdependent variable is 0)
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.intercept_
								</div>
								<div class="codeoutput">
									-350.73719181213653
								</div>

								<div class="markdown">
									&bull; ...function that predicts values (y = m * x + b)
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.predict( <span class="usermade">70</span> )
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.predict( [ [ <span class="usermade">70</span> ] ] )
								</div>
								<div class="codeoutput">
									array([ 189.47294304])
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.predict( [ [ <span class="usermade">70</span> ],[ <span class="usermade">80</span> ] ] )
								</div>
								<div class="codeoutput">
									array([ 189.47294304,  266.64581945])
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.predict( <span class="usermade">ourdataframe</span>[ [ <span class="usermade">"Height"</span> ] ] )
								</div>
								<div class="codeoutput">
									<span class="pre">array([ 219.16147993,  180.07254619,  221.19180859, ...,  142.15047514,</span>
									<br/><span class="pre">        182.01991949,  127.30437133])</span>
								</div>

								<div class="markdown">
									&bull; ...for SIMPLE LINEAR REGRESSION, plot the linear regression line on the scatter plot
									<br/># line style: <span class="usermade">'-'</span> line, '*' stars
									<br/># the scatter plot and the line are referring to the same matplotlib object, so they show up in the same plot
								</div>
								<div class="codeinput">
									## %matplotlib inline
									<br/>import matplotlib.pyplot as plt
									<br/>
									<br/><span class="usermade">ourdataframe</span>.plot( kind="scatter",x=<span class="usermade">"Height"</span>,y=<span class="usermade">"Weight"</span> )
									<br/>plt.plot( <span class="usermade">ourdataframe</span>[<span class="usermade">"Height"</span>],<span class="temp">ourmodel</span>.predict( <span class="usermade">ourdataframe</span>[ [ <span class="usermade">"Height"</span> ] ] ),<span class="usermade">"-"</span> )
									<br/>
									<br/>plt.show()
								</div>
								<div class="codeinput">
									## %matplotlib inline
									<br/>import matplotlib.pyplot as plt
									<br/>
									<br/><span class="usermade">ourdataframe</span>.plot( kind="scatter",x=<span class="usermade">"Height"</span>,y=<span class="usermade">"Weight"</span>,alpha=<span class="usermade">.2</span> )
									<br/>plt.plot( <span class="usermade">ourdataframe</span>[<span class="usermade">"Height"</span>],<span class="temp">ourmodel</span>.predict( <span class="usermade">ourdataframe</span>[ [ <span class="usermade">"Height"</span> ] ] ),<span class="usermade">"-"</span>,color=<span class="usermade">"red"</span> )
									<br/>
									<br/>plt.show()
								</div>
								<div class="markdown">
									3D
								</div>
								<div class="codeinput">
									## %matplotlib inline
									<br/>import matplotlib.pyplot as plt
									<br/>from mpl_toolkits.mplot3d import Axes3D
									<br/>
									<br/><span class="temp">ourfigure</span> = plt.figure()
									<br/><span class="comment"># </span>
									<br/><span class="temp">oursubplot</span> = <span class="temp">ourfigure</span>.add_subplot( 1,1,1,projection="3d" )
									<br/><span class="temp">oursubplot</span>.set_xlabel( <span class="usermade">"LATE_AIRCRAFT_DELAY"</span> )
									<br/><span class="temp">oursubplot</span>.set_ylabel( <span class="usermade">"CARRIER_DELAY"</span> )
									<br/><span class="temp">oursubplot</span>.set_zlabel( <span class="usermade">"DEP_DELAY"</span> )
									<br/><span class="comment"># </span>
									<br/><span class="temp">oursubplot</span>.scatter( <span class="usermade">ourdataframe</span>[<span class="usermade">"LATE_AIRCRAFT_DELAY"</span>],<span class="usermade">ourdataframe</span>[<span class="usermade">"CARRIER_DELAY"</span>],<span class="usermade">ourdataframe</span>[<span class="usermade">"DEP_DELAY"</span>],alpha=<span class="usermade">.2</span> )
									<br/>plt.plot( <span class="usermade">ourdataframe</span>[<span class="usermade">"LATE_AIRCRAFT_DELAY"</span>],<span class="usermade">ourdataframe</span>[<span class="usermade">"CARRIER_DELAY"</span>],<span class="temp">ourmodel</span>.predict( <span class="usermade">ourdataframe</span>[ [ <span class="usermade"><span class="usermade">"LATE_AIRCRAFT_DELAY"</span></span>,<span class="usermade">"CARRIER_DELAY"</span> ] ] ),<span class="usermade">"*"</span>,color=<span class="usermade">"red"</span> )
									<br/>
									<br/>plt.show()
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
									<br/>using `statsmodels`
									<br/># We want Weight in terms of Height # For Weight in terms of Height and Age, "Weight~Height+Age"
								</div>
								<div class="codeinput">
									<span class="extracode">
										import pandas as pd
										<br/>ourdataframe = pd.read_csv( "heights_weights_genders.csv" )
									</span>
									<br/>import statsmodels.formula.api as smf
									<br/><span class="temp">ourmodel</span> = smf.ols( "<span class="usermade">Weight</span>~<span class="usermade">Height</span>",data=<span class="usermade">ourdataframe</span> ).fit()
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull;  # Look for "R-squared"
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.summary()
								</div>
								<div class="codeoutput">
									<span class="pre">                            OLS Regression Results                            </span>
									<br/><span class="pre">==============================================================================</span>
									<br/><span class="pre">Dep. Variable:                 Weight   R-squared:                       0.855</span>
									<br/><span class="pre">Model:                            OLS   Adj. R-squared:                  0.855</span>
									<br/><span class="pre">Method:                 Least Squares   F-statistic:                 5.904e+04</span>
									<br/><span class="pre">Date:                Sat, 08 Aug 2015   Prob (F-statistic):               0.00</span>
									<br/><span class="pre">Time:                        23:31:09   Log-Likelihood:                -39219.</span>
									<br/><span class="pre">No. Observations:               10000   AIC:                         7.844e+04</span>
									<br/><span class="pre">Df Residuals:                    9998   BIC:                         7.846e+04</span>
									<br/><span class="pre">Df Model:                           1                                         </span>
									<br/><span class="pre">Covariance Type:            nonrobust                                         </span>
									<br/><span class="pre">==============================================================================</span>
									<br/><span class="pre">                 coef    std err          t      P>|t|      [95.0% Conf. Int.]</span>
									<br/><span class="pre">------------------------------------------------------------------------------</span>
									<br/><span class="pre">Intercept   -350.7372      2.111   -166.109      0.000      -354.876  -346.598</span>
									<br/><span class="pre">Height         7.7173      0.032    242.975      0.000         7.655     7.780</span>
									<br/><span class="pre">==============================================================================</span>
									<br/><span class="pre">Omnibus:                        2.141   Durbin-Watson:                   1.677</span>
									<br/><span class="pre">Prob(Omnibus):                  0.343   Jarque-Bera (JB):                2.150</span>
									<br/><span class="pre">Skew:                           0.036   Prob(JB):                        0.341</span>
									<br/><span class="pre">Kurtosis:                       2.991   Cond. No.                     1.15e+03</span>
									<br/><span class="pre">==============================================================================</span>
									<br/><span class="pre"></span>
									<br/><span class="pre">Warnings:</span>
									<br/><span class="pre">[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</span>
									<br/><span class="pre">[2] The condition number is large, 1.15e+03. This might indicate that there are</span>
									<br/><span class="pre">strong multicollinearity or other numerical problems.</span>
								</div>

								<div class="markdown">
									&bull; ...slope (m) &amp; intercept (b)
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.params
								</div>
								<div class="codeoutput">
									<span class="pre">Intercept   -350.737192</span>
									<br/><span class="pre">Height         7.717288</span>
									<br/><span class="pre">dtype: float64</span>
								</div>

								<div class="markdown">
									slope (m)
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.params[<span class="usermade">"Height"</span>]
								</div>
								<div class="codeoutput">
									7.7172876407853712
								</div>

								<div class="markdown">
									intercept (b)
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.params[<span class="usermade">"Intercept"</span>]
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.params[<span class="usermade">0</span>]
								</div>
								<div class="codeoutput">
									-350.73719181213835
								</div>

								<div class="markdown">
									&bull; ...function that predicts values (y = m * x + b)
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.predict( { <span class="usermade">"Height"</span>:<span class="usermade">70</span> } )
								</div>
								<div class="codeoutput">
									array([ 189.47294304])
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.predict( { <span class="usermade">"Height"</span>:[ <span class="usermade">70</span>,<span class="usermade">80</span> ] } )
								</div>
								<div class="codeoutput">
									array([ 189.47294304,  266.64581945])
								</div>
								<div class="codeinput">
									<span class="extracode">print</span> <span class="temp">ourmodel</span>.predict( <span class="usermade">ourdataframe</span>[ [ <span class="usermade">"Height"</span> ] ] )
								</div>
								<div class="codeoutput">
									<span class="pre">array([ 219.16147993,  180.07254619,  221.19180859, ...,  142.15047514,</span>
									<br/><span class="pre">        182.01991949,  127.30437133])</span>
								</div>

								<div class="markdown">
									&bull; ...plotting
								</div>
								<div class="codeinput">
									## %matplotlib inline
									<br/>import matplotlib.pyplot as plt
									<br/>
									<br/><span class="usermade">ourdataframe</span>.plot( kind="scatter",x=<span class="usermade">"Height"</span>,y=<span class="usermade">"Weight"</span> )
									<br/>plt.plot( <span class="usermade">ourdataframe</span>[<span class="usermade">"Height"</span>],<span class="temp">ourmodel</span>.predict( <span class="usermade">ourdataframe</span>[ [ <span class="usermade">"Height"</span> ] ] ),<span class="usermade">'-'</span> )
									<br/>
									<br/>plt.show()
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-defi" id="defi_classification">
						<div class="markdown">
							CLASSIFICATION

							<br/>
							<br/>lots of data problems in journalism are secretly classification problems:

							<br/># sorting through documents
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;# https://github.com/cjdd3b/nicar2014/tree/master/lightning-talk/naive-bayes

							<br/># extracting quotes from news articles
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;# https://github.com/cjdd3b/citizen-quotes
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;# no scare quotes, quotes that begin mid sentence, 
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;# regular expressions, yeah good luck with that, but also classifiers

							<br/># doc classifier
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;# deliberately over-publicizing drug related busts along the Mexican border to appear tough on immigration?
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;# counts based on  checkpoints
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;marijuana, meth synonyms
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;data source: scraped
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;Arthur: Can we do a project from start to finish?

							<br/># Roger: doctor, medical disciplinary board

							<br/># ProPublica's Message Machine

							<br/># LA Times NLP in the kitchen, max ent model

							<br/>
							<br/># predicting fuzzy things # if it's not fuzzy, it's probably overfitting

							<br/>
							<br/># SUPERVISED LEARNING MODEL
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;# CLASSIFICATION TASK
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# LOGISTIC REGRESSION
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# NAIVE BAYES is less accurate (MULTINOMIAL, GAUSSIAN)
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# SUPPORT VECTOR MACHINEs takes forever to train, like 6 hrs
							<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# RANDOM FOREST

							<br/>
							<br/>features to feed to a classifier:
							<br/># continuous value (0 to 1) for similarity score
							<br/># discrete value (True, False, or NaN) (1, -1, or 0)
						</div>
					</div>

					<div class="boxcontent box-code" id="code_logistic_regression">
						<div class="boxtitle">
							LOGISTIC REGRESSION
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
									<br/># Let's do a simple logistic regression to predict survival (<span class="usermade">"survived"</span>) based on <span class="usermade">"pclass"</span> and <span class="usermade">"sex"</span>
									<br/># Remember we drop one value in each dummy to avoid the dummy variable trap
								</div>
								<div class="codeinput">
									<span class="extracode">
										import pandas as pd
										<br/>ourdataframe = pd.read_csv( "titanic.csv" )
									</span>
									<br/>from sklearn.linear_model import LogisticRegression
									<br/><span class="usermade">ourdataframe</span> = <span class="usermade">ourdataframe</span>.join( pd.get_dummies( <span class="usermade">ourdataframe</span>[<span class="usermade">"pclass"</span>],prefix=<span class="usermade">"pclass"</span> ) )
									<br/><span class="usermade">ourdataframe</span> = <span class="usermade">ourdataframe</span>.join( pd.get_dummies( <span class="usermade">ourdataframe</span>[<span class="usermade">"sex"</span>],prefix=<span class="usermade">"sex"</span> ) )
									<br/><span class="temp">train_x</span> = <span class="usermade">ourdataframe</span>[ [ <span class="usermade">"pclass_2nd"</span>,<span class="usermade">"pclass_3rd"</span>,<span class="usermade">"sex_male"</span> ] ]
									<br/><span class="temp">ourmodel</span> = LogisticRegression().fit( <span class="temp">train_x</span>,<span class="usermade">ourdataframe</span>[<span class="usermade">"survived"</span>] )
								</div>
								<div class="codeinput">
									<span class="extracode">
										import pandas as pd
										<br/>ourdataframe = pd.read_csv( "titanic.csv" )
									</span>
									<br/>from sklearn.linear_model import LogisticRegression
									<br/><span class="temp">train_x</span> = pd.concat( [ pd.get_dummies( <span class="usermade">ourdataframe</span>[<span class="temp">c</span>],prefix=<span class="temp">c</span> ).ix[:,1:] &nbsp;for <span class="temp">c</span> in [ <span class="usermade">"pclass"</span>,<span class="usermade">"sex"</span> ] ],axis=1 )
									<br/><span class="temp">ourmodel</span> = LogisticRegression().fit( <span class="temp">train_x</span>,<span class="usermade">ourdataframe</span>[<span class="usermade">"survived"</span>] )
								</div>

								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									<span class="temp">ourmodel</span>.score( <span class="temp">train_x</span>,<span class="usermade">ourdataframe</span>[<span class="usermade">"survived"</span>] )
								</div>
								<div class="codeoutput">
								</div>
								<div class="codeinput">
									<span class="usermade">ourdataframe</span>[<span class="usermade">"survived"</span>].mean()
								</div>
								<div class="codeoutput">
								</div>
								<div class="markdown">
									shape (number of classes, number of features)
								</div>
								<div class="codeinput">
									<span class="temp">ourmodel</span>.coef_
								</div>
								<div class="codeinput">
									pd.DataFrame( <span class="temp">ourmodel</span>.coef_,index=[ <span class="usermade">"survived"</span> ],columns=<span class="temp">train_x</span>.columns )
								</div>
								<div class="codeoutput">
								</div>
								<div class="codeinput">
									<span class="temp">ourmodel</span>.intercept_
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_decision_tree">
						<div class="boxtitle">
							DECISION TREE
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
									<span class="extracode">
										from sklearn import datasets
										<br/>ourdataset = datasets.load_iris()
									</span>
									<br/>from sklearn.tree import DecisionTreeClassifier
									<br/><span class="temp">ourmodel</span> = DecisionTreeClassifier().fit( <span class="usermade">ourdataset.data</span>,<span class="usermade">ourdataset.target</span> )
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull; split data set into training data set &amp; testing data set; train on training data...
								</div>
								<div class="codeinput">
									<span class="extracode">
										from sklearn import datasets
										<br/>ourdataset = datasets.load_iris()
									</span>
									<br/><span class="temp">full_x</span> = <span class="usermade">ourdataset.data</span>
									<br/><span class="temp">full_y</span> = <span class="usermade">ourdataset.target</span>
									<br/>from sklearn.cross_validation import train_test_split
									<br/><span class="temp">train_x</span>,<span class="temp">test_x</span>,<span class="temp">train_y</span>,<span class="temp">test_y</span> = train_test_split( <span class="temp">full_x</span>,<span class="temp">full_y</span>,train_size=<span class="usermade">0.66</span>,test_size=<span class="usermade">0.33</span> )
									<br/>
									<br/>from sklearn.tree import DecisionTreeClassifier
									<br/><span class="temp">ourmodel</span> = DecisionTreeClassifier().fit( <span class="temp">train_x</span>,<span class="temp">train_y</span> )
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull; ...test on test data
								</div>
								<div class="markdown">
									accuracy # float
								</div>
								<div class="codeinput">
									from sklearn import metrics
									<br/><span class="extracode">print</span> metrics.accuracy_score( <span class="temp">test_y</span>,<span class="temp">ourmodel</span>.predict( <span class="temp">test_x</span> ) )
								</div>
								<div class="codeoutput">
									0.92000000000000004
								</div>

								<div class="markdown">
									classification report: precision, recall, f1-score, support # string
								</div>
								<div class="codeinput">
									from sklearn import metrics
									<br/><span class="extracode">print</span> metrics.classification_report( <span class="temp">test_y</span>,<span class="temp">ourmodel</span>.predict( <span class="temp">test_x</span> ) )
								</div>
								<div class="codeoutput">
									<span class="pre">             precision    recall  f1-score   support</span>
									<br/>
									<br/><span class="pre">          0       1.00      1.00      1.00        14</span>
									<br/><span class="pre">          1       0.86      0.95      0.90        19</span>
									<br/><span class="pre">          2       0.93      0.82      0.87        17</span>
									<br/>
									<br/><span class="pre">avg / total       0.92      0.92      0.92        50</span>
								</div>

								<div class="markdown">
									confusion matrix # np.array
								</div>
								<div class="codeinput">
									from sklearn import metrics
									<br/><span class="extracode">print</span> metrics.confusion_matrix( <span class="temp">test_y</span>,<span class="temp">ourmodel</span>.predict( <span class="temp">test_x</span> ) )
								</div>
								<div class="codeoutput">
									<span class="pre">array([[14,  0,  0],</span>
									<br/><span class="pre">       [ 0, 18,  1],</span>
									<br/><span class="pre">       [ 0,  3, 14]])</span>
								</div>

								<div class="markdown">
									&bull; ...prediction function
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
								</div>
								<div class="codeinput">
									ourmodel.feature_importances_
								</div>
								<div class="codeoutput">
									array([ 0.        ,  0.        ,  0.41104635,  0.58895365])
								</div>

								<div class="markdown">
									&bull; ...plotting
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull; ...visualize
									<br/>In terminal, # in that order # Windows: first install .msi file, then run?
								</div>
								<div class="codeinput">
									brew install graphviz
									<br/>pip install pydotplus
								</div>
								<div class="markdown">
									In our code, [save]
								</div>
								<div class="codeinput">
									from sklearn.externals.six import StringIO
									<br/>from sklearn.tree import export_graphviz
									<br/>import pydotplus
									<br/><span class="temp">ourdotdata</span> = StringIO()
									<br/>export_graphviz( <span class="temp">ourmodel</span>,out_file=<span class="temp">ourdotdata</span> )
									<br/>pydotplus.graph_from_dot_data( <span class="temp">ourdotdata</span>.getvalue() ).write_png( <span class="usermade">"ourchart.png"</span> )
								</div>
								<div class="markdown">
									[&amp; show]
								</div>
								<div class="codeinput">
									<br/>from PIL import Image
									<br/>Image.open( <span class="usermade">"ourchart.png"</span> ).show()
								</div>
								<div class="markdown">
									[&amp; show in iPython]
								</div>
								<div class="codeinput">
									<br/>%matplotlib inline
									<br/>from IPython.display import Image
									<br/>Image( filename=( <span class="usermade">"ourchart.png"</span> ) )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_naive_bayes">
						<div class="boxtitle">
							NAIVE BAYES
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull; multinomial naive bayes
								</div>
								<div class="codeinput">
									from sklearn.naive_bayes import MultinomialNB
									<br/>ourmodel_mult = MultinomialNB().fit( train_x,train_y )
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									&bull; Gaussian naive bayes
								</div>
								<div class="codeinput">
									from sklearn.naive_bayes import GaussianNB
									<br/>ourmodel_gaus = GaussianNB().fit( train_x,train_y )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_knn">
						<div class="boxtitle">
							K NEAREST NEIGHBORS
						</div>
						<div class="markdown">
							Advantages
							<br/> Simple to implement and use
							<br/> Comprehensible  easy to explain prediction
							<br/> Robust to noisy data by averaging k-nearest neighbors
							<br/> Distance function can be tailored using domain knowledge
							<br/> Can learn complex decision boundaries
							<br/>
							<br/>Disadvantages
							<br/> Need a lot of space to store all examples
							<br/> Takes much more time to classify a new example than with a parsimonious model (need to compare distance to all other examples)
							<br/> Distance function must be designed carefully with domain knowledge
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
									from sklearn.neighbors import KNeighborsClassifier
									<br/>ourmodel = KNeighborsClassifier( n_neighbors=5 ).fit( train_x,train_y )
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									# We can also tune this a bit by not weighting each instance the same, but decreasing the weight as the distance increases
								</div>
								<div class="codeinput">
									from sklearn.neighbors import KNeighborsClassifier 
									<br/>ourmodel = KNeighborsClassifier( n_neighbors=5,weights='distance' ).fit( train_x,train_y )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-exam" id="exam_iris_data">
						<div class="boxtitle">
							IRIS DATA
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									0: loading &amp; exploring data
								</div>
								<div class="codeinput">
									<span class="extracode">
										from sklearn import datasets
										<br/>ourdataset = datasets.load_iris()
									</span>
								</div>

								<div class="markdown">
									&bull; just an aside about the iris data
									# classic data set (like the grasshopper katydids data set is classic)
								</div>
								<div class="codeinput">
									print dict( ourdataset ).keys()
								</div>
								<div class="codeoutput">
									['DESCR', 'data', 'target', 'target_names', 'feature_names']
								</div>
								<div class="codeinput">
									ourdataset.DESCR
								</div>
								<div class="codeoutput">
								</div>
								<div class="codeinput">
									ourdataset.data
									<br/>ourdataset.feature_names
								</div>
								<div class="codeoutput">
									['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
								</div>
								<div class="codeinput">
									ourdataset.target
									<br/>ourdataset.target_names
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									1: getting features 
								</div>
								<div class="markdown">
									&bull; split data set into training data set &amp; test data set (try 50%-50%, 66%-33%, 75%-25%)
								</div>
								<div class="codeinput">
									<span class="temp">full_x</span> = <span class="usermade">ourdataset.data</span>
									<br/><span class="temp">full_y</span> = <span class="usermade">ourdataset.target</span>
									<br/>from sklearn.cross_validation import train_test_split
									<br/><span class="temp">train_x</span>,<span class="temp">test_x</span>,<span class="temp">train_y</span>,<span class="temp">test_y</span> = train_test_split( <span class="temp">full_x</span>,<span class="temp">full_y</span>,train_size=<span class="usermade">0.66</span>,test_size=<span class="usermade">0.33</span> )
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									2: training our model 
								</div>
								<div class="markdown">
									&bull; training on all the data...
								</div>
								<div class="codeinput">
									from sklearn.tree import DecisionTreeClassifier
									<br/><span class="temp">ourmodel</span> = DecisionTreeClassifier().fit( <span class="temp">full_x</span>,<span class="temp">full_y</span> )
								</div>

								<div class="markdown">
									&bull; training on training data...
								</div>
								<div class="codeinput">
									from sklearn.tree import DecisionTreeClassifier
									<br/><span class="temp">ourmodel</span> = DecisionTreeClassifier().fit( <span class="temp">train_x</span>,<span class="temp">train_y</span> )
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									&bull; cross validation # np.array
								</div>
								<div class="markdown">
									# on the full data set, 
									# average it out, # for unseen data
								</div>
								<div class="codeinput">
									from sklearn.cross_validation import cross_val_score
									<br/><span class="extracode">ourscores =</span> cross_val_score( DecisionTreeClassifier(),<span class="temp">full_x</span>,<span class="temp">full_y</span>,cv=<span class="usermade">10</span>,scoring=<span class="usermade">"accuracy"</span> )
								</div>
								<div class="codeoutput">
									<span class="pre">array([ 1.        ,  0.93333333,  1.        ,  0.93333333,  0.93333333,</span>
									<br/><span class="pre">        0.86666667,  0.93333333,  1.        ,  1.        ,  1.        ])</span>
								</div>

								<div class="markdown">
								</div>
								<div class="codeinput">
									from sklearn.cross_validation import cross_val_score
									<br/><span class="extracode">ourscores =</span> cross_val_score( DecisionTreeClassifier(),<span class="temp">test_x</span>,<span class="temp">test_y</span>,cv=<span class="usermade">10</span>,scoring=<span class="usermade">"accuracy"</span> )
								</div>
								<div class="codeoutput">
									<span class="pre">array([ 0.83333333,  0.83333333,  0.83333333,  0.66666667,  0.83333333,</span>
									<br/><span class="pre">        0.83333333,  1.        ,  0.66666667,  1.        ,  1.        ])</span>
								</div>

								<div class="markdown">
									Perform 10-fold cross validation on the data and compare your results to the hold out method. Take the average of the results. What do you notice about the accuracy measures in each of these?
								</div>
								<div class="codeinput">
									ourscores.mean()
								</div>
								<div class="codeoutput">
									0.94000000000000006
								</div>
								<div class="markdown">
									Based on this result, it's likely our model will achieve a 94% accuracy on unseen data, rather than the 97% predicted with the hold-out method
								</div>

							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									3: scoring, parameters, predicting, visualizaing
								</div>
								<div class="markdown">
									&bull; ...test on test data
								</div>
								<div class="markdown">
									accuracy # float
								</div>
								<div class="codeinput">
									from sklearn import metrics
									<br/><span class="extracode">print</span> metrics.accuracy_score( <span class="temp">test_y</span>,<span class="temp">ourmodel</span>.predict( <span class="temp">test_x</span> ) )
								</div>
								<div class="codeoutput">
									0.93999999999999995
								</div>

								<div class="markdown">
									classification report: precision, recall, f1-score, support # string
								</div>
								<div class="codeinput">
									from sklearn import metrics
									<br/><span class="extracode">print</span> metrics.classification_report( <span class="temp">test_y</span>,<span class="temp">ourmodel</span>.predict( <span class="temp">test_x</span> ) )
								</div>
								<div class="codeoutput">
									<span class="pre">             precision    recall  f1-score   support</span>
									<br/>
									<br/><span class="pre">          0       1.00      1.00      1.00        16</span>
									<br/><span class="pre">          1       0.94      0.88      0.91        17</span>
									<br/><span class="pre">          2       0.89      0.94      0.91        17</span>
									<br/>
									<br/><span class="pre">avg / total       0.94      0.94      0.94        50</span>
								</div>

								<div class="markdown">
									confusion matrix # np.array
								</div>
								<div class="codeinput">
									from sklearn import metrics
									<br/><span class="extracode">print</span> metrics.confusion_matrix( <span class="temp">test_y</span>,<span class="temp">ourmodel</span>.predict( <span class="temp">test_x</span> ) )
								</div>
								<div class="codeoutput">
									<span class="pre">array([[16,  0,  0],</span>
									<br/><span class="pre">       [ 0, 15,  2],</span>
									<br/><span class="pre">       [ 0,  1, 16]])</span>
								</div>

								<div class="markdown">
									&bull; ...test on <em>training</em> data (what happens?)
								</div>
								<div class="markdown">
									accuracy # float
								</div>
								<div class="codeinput">
									from sklearn import metrics
									<br/><span class="extracode">print</span> metrics.accuracy_score( <span class="temp">train_y</span>,<span class="temp">ourmodel</span>.predict( <span class="temp">train_x</span> ) )
								</div>
								<div class="codeoutput">
									1.0
								</div>

								<div class="markdown">
									classification report: precision, recall, f1-score, support # string
								</div>
								<div class="codeinput">
									from sklearn import metrics
									<br/><span class="extracode">print</span> metrics.classification_report( <span class="temp">train_y</span>,<span class="temp">ourmodel</span>.predict( <span class="temp">train_x</span> ) )
								</div>
								<div class="codeoutput">
									<span class="pre">             precision    recall  f1-score   support</span>
									<br/>
									<br/><span class="pre">          0       1.00      1.00      1.00        33</span>
									<br/><span class="pre">          1       1.00      1.00      1.00        33</span>
									<br/><span class="pre">          2       1.00      1.00      1.00        33</span>
									<br/>
									<br/><span class="pre">avg / total       1.00      1.00      1.00        99</span>
								</div>

								<div class="markdown">
									confusion matrix # np.array
								</div>
								<div class="codeinput">
									from sklearn import metrics
									<br/><span class="extracode">print</span> metrics.confusion_matrix( <span class="temp">train_y</span>,<span class="temp">ourmodel</span>.predict( <span class="temp">train_x</span> ) )
								</div>
								<div class="codeoutput">
									<span class="pre">array([[33,  0,  0],</span>
									<br/><span class="pre">       [ 0, 33,  0],</span>
									<br/><span class="pre">       [ 0,  0, 33]])</span>
								</div>

								<div class="markdown">
									very high, because we're just "testing" on the training data
									<br/>why not 100% sometimes? there's some default setting that doesn't train 100%
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-exam" id="exam_seeds_data">
						<div class="boxtitle">
							SEEDS DATA
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								0: loading &amp; exploring data
							</div>

							<div class="subchunk">
								<div class="markdown">
									Open the seeds_dataset.txt and perform basic exploratory analysis. What attributes to we have? What are we trying to predict?
									<br/>For context of the data, see the documentation here: https://archive.ics.uci.edu/ml/datasets/seeds
								</div>
								<div class="markdown">
									https://raw.githubusercontent.com/datapolitan/lede_algorithms/master/class3_2/data/seeds_dataset.txt
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/>df = pd.read_csv( 'seeds_dataset.txt',header=None,names=[ "area","perimeter","compactness","length of kernel","width of kernel","asymmetry coefficient","length of kernel groove","variety of wheat" ] )
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/>from urllib2 import Request,urlopen
									<br/>df = pd.read_csv( urlopen( Request( "https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt" ) ),delim_whitespace=True,header=None,names=[ "area","perimeter","compactness","length of kernel","width of kernel","asymmetry coefficient","length of kernel groove","variety of wheat" ] )
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									df.describe()
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									from pandas.tools.plotting import scatter_matrix
									<br/>scatter_matrix( df,alpha=0.2, figsize=( 10,10 ),diagonal='kde' )
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									df.corr()
								</div>
								<div class="codeoutput">
								</div>
								<div class="markdown">
									based on the various characteristics of the wheat kernel, we're predicting the variety, either Kama, Rosa and Canadian.
									<br/>Some features seem highly correlated and potentially useful for splitting features (area and perimeter),
									<br/>while others don't appear correlated and unlikely to help split features (asymetry coefficient)
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								1: getting features
							</div>

							<div class="subchunk">
								<div class="markdown">
									<span class="usermade">0.5</span>, <span class="usermade">0.75</span>
								</div>
								<div class="codeinput">
									full_x = df[ [ "area","perimeter","compactness","length of kernel","width of kernel","asymmetry coefficient","length of kernel groove" ] ]
									<br/>full_y = df["variety of wheat"]
									<br/>from sklearn.cross_validation import train_test_split 
									<br/>train_x,test_x,train_y,test_y = train_test_split( full_x,full_y,train_size=<span class="usermade">0.5</span> ) 
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								2: training our model
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									from sklearn.tree import DecisionTreeClassifier
									<br/>ourmodel = DecisionTreeClassifier().fit( train_x,train_y )
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									cross validation
								</div>
								<div class="codeinput">
									from sklearn.cross_validation import cross_val_score
									<br/>ourscores = cross_val_score( ourmodel,full_x,full_y,cv=10 )
								</div>
								<div class="codeinput">
									ourscores.mean()
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								3: testing our model
							</div>

							<div class="subchunk">
								<div class="markdown">
									accuracy, classification report, confusion matrix with training data and test data
									<br/>feature importances with full data (only?)
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									50%-50%: class 1 and 3 are hard for the classifier to distinguish, which makes sense looking at the scatter matrix results and seeing the overlap between them
									<br/>75%-25%: Although the precision and recall for class 3 have improved, there's still a problem in having the model distinguish between classes 1 and 3
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-exam" id="exam_donor_names_data">
						<div class="boxtitle">
							DONOR NAMES DATA
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									0: loading &amp; exploring data
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/>train = pd.read_csv( "contribs_training.csv" )
									<br/>test&nbsp; = pd.read_csv( "contribs_unclassified.csv" )
								</div>
								<div class="markdown">
								</div>
								<div class="codeinput">
									train.columns
								</div>
								<div class="codeoutput">
									<span class="pre">Index([u'contributor_ext_id', u'name', u'address', u'city', u'state',</span>
									<br/><span class="pre">       u'zip_code', u'occupation', u'employer', u'entity_tp'],</span>
									<br/><span class="pre">      dtype='object')</span>
								</div>
								<div class="markdown">
								</div>
								<div class="codeinput">
									test.columns
								</div>
								<div class="codeoutput">
									<span class="pre">Index([u'name', u'candidate', u'fecid', u'last_name', u'first_name',</span>
									<br/><span class="pre">       u'middle_name', u'city', u'state', u'zip', u'employer', u'occupation',</span>
									<br/><span class="pre">       u'amount', u'date'],</span>
									<br/><span class="pre">      dtype='object')</span>
								</div>
								<div class="markdown">
									edit the test data columns/entries to look like the training data columns (trying to see how good the model is for data that looks like the training data)
									<br/>(If we were trying to maximize just the test result, )
								</div>
								<div class="markdown fullunderscore">
									<span class="pre">train                    test</span>
									<br/><span class="pre">u'contributor_ext_id',---</span>
									<br/><span class="pre">u'name',-----------------u'last_name', u'first_name', u'middle_name',</span>
									<br/><span class="pre">u'address',--------------</span>
									<br/><span class="pre">u'city',-----------------u'city',</span>
									<br/><span class="pre">u'state',----------------u'state'</span>
									<br/><span class="pre">u'zip_code', ------------u'zip'</span>
									<br/><span class="pre">u'occupation',-----------u'occupation',</span>
									<br/><span class="pre">u'employer',-------------u'employer'</span>
									<br/><span class="pre">u'entity_tp'-------------</span>
									<br/><span class="pre">-------------------------u'name', u'candidate', u'fecid', u'amount', u'date'</span>
								</div>
								<div class="markdown">
									dealing with `NaN`s:
								</div>
								<div class="codeinput">
									from numpy import isnan
									<br/>notnan = lambda x: not ( isinstance( x,float ) and isnan( x ) )
								</div>
								<div class="codeinput">
									<span class="comment"># "donorname"</span>
									<br/>train = train.rename( columns={ "name":"donorname" } )
									<br/>test["donorname"] = test["last_name"].apply( lambda s: str( s ) if notnan( s ) &nbsp;else "" ) + test["first_name"].apply( lambda s: ", "+str( s ) if notnan( s ) &nbsp;else "" ) + test["middle_name"].apply( lambda s: " "+str( s ) if notnan( s ) &nbsp;else "" )
									<br/><span class="comment"># "city"</span>
									<br/><span class="comment"># "state"</span>
									<br/><span class="comment"># "zipcode"</span>
									<br/>train = train.rename( columns={ "zip_code":"zipcode" } )
									<br/>test&nbsp; = test.rename( columns={ "zip":"zipcode" } )
									<br/><span class="comment"># "occupation"</span>
									<br/><span class="comment"># "employer"</span>
								</div>
							</div>
						</div>

		 				<div class="chunk">
		 					<div class="subchunk">
								<div class="markdown">
									1: getting features
									<br/>###### this is an example where these 
									<br/>###### in the interest of time, do these here once and not over and over again below
								</div>
								<div class="codeinput aside">
									from nameparser import HumanName
									<br/>HumanName( "RALES, JOSHUA B" )
								</div>
								<div class="codeoutput">
									<span class="pre">&lt;HumanName : [</span>
									<br/><span class="pre">	title: '' </span>
									<br/><span class="pre">	first: 'JOSHUA' </span>
									<br/><span class="pre">	middle: 'B' </span>
									<br/><span class="pre">	last: 'RALES' </span>
									<br/><span class="pre">	suffix: ''</span>
									<br/><span class="pre">	nickname: ''</span>
									<br/><span class="pre">]&GT;</span>
								</div>
								<div class="codeinput">
									<span class="comment"># "donorname"</span>
									<br/>from nameparser import HumanName
									<br/>train["feature_donorname"] = train["donorname"].apply( lambda s: HumanName( s.strip().lower() ) )
									<br/>test["feature_donorname"]&nbsp; = test["donorname"].apply( lambda s: HumanName( s.strip().lower() ) )
								</div>
								<div class="codeinput">
									train["feature_donorname_first"] = train["feature_donorname"].apply( lambda n: n.first )
									<br/>test["feature_donorname_first"]&nbsp; = test["feature_donorname"].apply( lambda n: n.first )
									<br/>train["feature_donorname_last"] = train["feature_donorname"].apply( lambda n: n.last )
									<br/>test["feature_donorname_last"]&nbsp; = test["feature_donorname"].apply( lambda n: n.last )
								</div>
								<div class="codeinput">
									<span class="comment"># "city"</span>
									<br/>train["feature_city"] = train["city"].apply( lambda s: s.strip().lower() )
									<br/>test["feature_city"]&nbsp; = test["city"].apply( lambda s: s.strip().lower() )
									<br/><span class="comment"># "state"</span>
									<br/>train["feature_state"] = train["state"].apply( lambda s: s.strip().lower() )
									<br/>test["feature_state"]&nbsp; = test["state"].apply( lambda s: s.strip().lower() )
								</div>
								<div class="codeinput">
									<span class="comment"># "zipcode"</span>
									<br/>from numpy import isnan
									<br/>train["feature_zipcode"] = train["zipcode"].apply( lambda n: int( str( int( n ) )[:5] ) if notnan( n ) )  else n )
									<br/>test["feature_zipcode"]  = test["zipcode"].apply( lambda n: int( str( int( n ) )[:5] ) if notnan( n ) )  else n )
									<br/><span class="comment"># "occupation"</span>
									<br/><span class="comment"># "employer"</span>
								</div>

								<div class="markdown">
									some features we might use:
									<br/>e.g. population of the city they live in (two Joe Smiths from a highly populated city are more likely to be two different people, as opposed to two Joe Smiths from a less populated city who are likely to be the same) # we join data sets for this one
									<br/>e.g. gender based on first name
									<br/>e.g. name similarity, # `fuzzy` module
									<br/>e.g. similarity of the first name and not the whole name, the last name is pretty much always consistent anyway in campaign finance data
									<br/>e.g. "St Louis" and "Saint Louis"
									<br/>e.g. people sometimes mix up employer-occupation
									<br/>e.g. zip distance, work zip and home zip
									<br/>e.g. census data to see unusual names
									<br/>e.g. same gender; if they have the same address but have different gender, they are likely not the same person but husband and wife
									<br/>e.g. different state but same metro area e.g. NJ and NY
									<br/># continuous value (0 to 1) for similarity score
									<br/># discrete value (True, False, or NaN) (1, -1, or 0)
								</div>
								<div class="codeinput">
									def _shingle( word,n ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;'''
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;Splits words into shingles of size n.
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;Given word="shingle" and n=2, the output is a list that looks like :['sh', 'hi', 'in', 'ng', 'gl', 'le']
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;( More on shingling here: http://blog.mafr.de/2011/01/06/near-duplicate-detection/ )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;'''
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;return set( [ word[i:i+n]  for i in range( len( word ) - n + 1 ) ] )
									<br/>
									<br/>def _jaccard_sim(X, Y):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;'''
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;Jaccard similarity between two sets.
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;( Explanation here: http://en.wikipedia.org/wiki/Jaccard_index )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;'''
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;if not X or not Y:
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return 0
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;x = set( X )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;y = set( Y )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;return float( len( x &amp; y ) ) / len ( x | y )
									<br/>
									<br/>def sim( str1,str2,shingle_length=3 ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;'''
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;String similarity metric based on shingles and Jaccard.
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;'''
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;str1_shingles = _shingle( str1,shingle_length )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;str2_shingles = _shingle( str2,shingle_length )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;return _jaccard_sim( str1_shingles,str2_shingles )
									<br/>
									<br/>def ourfeaturevector( pair ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;return [ 
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;( pair[0]['feature_donorname'] == pair[1]['feature_donorname'] ), <span class="comment"># same name?</span>
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;( pair[0]['feature_zipcode']&nbsp;&nbsp; == pair[1]['feature_zipcode'] ),&nbsp;&nbsp; <span class="comment"># same zip code?</span>
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;( pair[0]['feature_donorname_first'] == pair[1]['feature_donorname_first'] ), <span class="comment"># same first name?</span>
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;( pair[0]['feature_donorname_last']&nbsp; == pair[1]['feature_donorname_last'] ),&nbsp; <span class="comment"># same last name?</span>
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;]
								</div>

								<div class="markdown">
									dataframe to list of dictionaries (need this for `itertools`?):
								</div>
								<div class="codeinput aside">
									<span class="usermade">ourdataframe</span>.T.to_dict().values()
								</div>
								<div class="codeinput aside">
									<span class="usermade">ourdataframe</span>.transpose().to_dict().values()
								</div>

								<div class="codeinput">
									import itertools
									<br/>
									<br/>train_x,train_y = [],[]
									<br/>for key,group in itertools.groupby( train.T.to_dict().values(),(lambda x: x['donorname'][:4]) ): 
									<br/><span class="comment">###### somewhat arbirary?</span>
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;for pair in itertools.combinations( group,2 ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;train_x.append( ourfeaturevector( pair ) )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;train_y.append( pair[0]['contributor_ext_id'] == pair[1]['contributor_ext_id'] )
									<br/>
									<br/>test_x,test_y_ish = [],[] 
									<br/><span class="comment">###### no `test_y`!</span>
									<br/>for key,group in itertools.groupby( test.T.to_dict().values(),(lambda x: x['donorname'][:4]) ): 
									<br/><span class="comment">###### somewhat arbirary?</span>
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;for pair in itertools.combinations( group,2 ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_x.append( ourfeaturevector( pair ) )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment"># test_y_ish.append( pair )</span>
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pairlist = []
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for p in pair:
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;valuelist = []
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for key in ( "first_name","middle_name","last_name", "state","city","zipcode", "employer","occupation", "fecid","name","candidate","amount","date", ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value = p[key]
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;valuelist.append( str( value ) if not ( isinstance( value,float ) and isnan( value ) )  else "" )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pairlist.append( ">> "+" | ".join( valuelist ) )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_y_ish.append( "\n".join( pairlist ) )
								</div>
							</div>
						</div>

		 				<div class="chunk">
		 					<div class="subchunk">
								<div class="markdown">
									2: training our model
								</div>
								<div class="codeinput">
									<span class="comment"># logistic regression</span>
									<br/>from sklearn.linear_model import LogisticRegression 
									<br/>ourmodel_logi = LogisticRegression().fit( train_x,train_y )
								</div>
								<div class="codeinput">
									<span class="comment"># decision tree</span>
									<br/>from sklearn.tree import DecisionTreeClassifier
									<br/>ourmodel_deci = DecisionTreeClassifier().fit( train_x,train_y )
								</div>
								<div class="codeinput">
									<span class="comment"># multinomial naive bayes</span>
									<br/>from sklearn.naive_bayes import MultinomialNB
									<br/>ourmodel_mult = MultinomialNB().fit( train_x,train_y )
								</div>
								<div class="codeinput">
									<span class="comment"># random forest</span>
									<br/>###### from sklearn.ensemble import RandomForestClassifier
									<br/>###### ourmodel_rand = RandomForestClassifier( n_estimators=10,random_state=0 ).fit( train_x,train_y )
								</div>
							</div>

		 					<div class="subchunk">
								<div class="markdown">
									evaluate model using 10-fold cross-validation
								</div>
								<div class="codeinput">
									from sklearn import cross_validation
								</div>
								<div class="codeinput">
									<span class="comment"># logistic regression</span>
									<br/>ourscores_logi = cross_validation.cross_val_score( ourmodel_logi,train_x,train_y,cv=10,scoring='f1' )
									<br/>print "%s (%s folds): %0.2f (+/- %0.2f) (logistic regression)" % ( 'F1',10,ourscores_logi.mean(),ourscores_logi.std() )
								</div>
								<div class="codeinput">
									<span class="comment"># decision tree</span>
									<br/>ourscores_deci = cross_validation.cross_val_score( ourmodel_deci,train_x,train_y,cv=10,scoring='f1' )
									<br/>print "%s (%s folds): %0.2f (+/- %0.2f) (decision tree)" % ( 'F1',10,ourscores_deci.mean(),ourscores_deci.std() )
								</div>
								<div class="codeinput">
									<span class="comment"># multinomial naive bayes</span>
									<br/>ourscores_mult = cross_validation.cross_val_score( ourmodel_mult,train_x,train_y,cv=10 )
									<br/>print "%s (%s folds): %0.2f (+/- %0.2f) (multinomial naive bayes)" % ( "Accuracy",10,ourscores_mult.mean(),ourscores_mult.std() )
								</div>
								<div class="codeinput">
									<span class="comment"># random forest</span>
								</div>
								<div class="codeinput">
									###### from sklearn.cross_validation import KFold
								</div>
							</div>
						</div>

		 				<div class="chunk">
		 					<div class="subchunk">
								<div class="markdown">
									3: scoring, <strike>parameters</strike>, predicting, <strike>visualizing</strike>
								</div>
								<div class="markdown">
									###### if we had normal `test_x`, `test_y`
								</div>
								<div class="codeinput">
									pred_from_test_x = ourmodel.predict( test_x )
									<br/>
									<br/>from sklearn import metrics 
									<br/>print metrics.accuracy_score( test_y,pred_from_test_x )
									<br/>print metrics.classification_report( test_y,pred_from_test_x )
									<br/>print metrics.confusion_matrix( test_y,pred_from_test_x )
									<br/>
									<br/>for t,p in zip( test_y,pred_from_test_x ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print "(actual)",t,"\t(prediction)",p
								</div>
								<div class="codeinput">
									<span class="comment"># decision tree</span>
									<br/><span class="comment"># logistic regression</span>
									<br/>for t,d,l in zip( test_y_ish,ourmodel_deci.predict( test_x ),ourmodel_logi.predict( test_x ) ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print "======================================================================"
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print t
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print d,"(decision tree)"
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print l,"(logistic regression)"
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-exam" id="exam_donor_occupations_data">
						<div class="boxtitle">
							DONOR OCCUPATIONS DATA
						</div>
						<div class="markdown">
							From a Times project that helps us standardize campaign finance data to enable new types of analyses. 
							<br/>There are 20 some odd things we look at to determine if two names are the same person; 

							<br/>
							<br/>1 thing is looking at their job category
							<br/>Classifying people's jobs based on strings representing their occupation and employer.
							Specifically, it tries to categorize 
							a free-form occupation/employer string into -> 
							a discrete job category (for example, the strings 
							"LAWYER" and "ATTORNEY" would both be categorized under -> 
							"LAW").
							<br/>This is DIMENSIONALITY REDUCTION

							<br/>
							<br/>These job categories were hand-labeled by Center for Responsive Politics (So what we're doing is SUPERVISED LEARNING).
							<br/>We're only attempting to classify the first character of the industry prefix ("A", "B", etc.) -- not the whole thing.
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								0: loading &amp; exploring data
							</div>

							<div class="subchunk">
								<div class="markdown">
									train is from a csv, test is just a list
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/>train = pd.read_csv( "category-training.csv",header=None,names=[ "occupation","employer","code" ] )
									<br/>test = [ "LAWYER","SKADDEN ARPS","CEO" ]
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
								</div>
								<div class="codeinput">
									train[ train.isnull().any( axis=1 ) ]
								</div>
								<div class="codeoutput">
								</div>
								<div class="codeinput">
									train[ train["occupation"].isnull() &amp; train["employer"].isnull() ]
								</div>
								<div class="codeoutput">
								</div>
								<div class="codeinput">
									train[ train["code"].isnull() ]
								</div>
								<div class="codeoutput">
								</div>
								<div class="markdown">
									# So we want only the rows where "occupation" is not NaN and/or "employer" is not NaN and where "code" is not NaN
								</div>
								<div class="codeinput">
									train = train[ ( train["occupation"].notnull() | train["employer"].notnull() ) &amp; train["code"].notnull() ]
								</div>
								<div class="codeoutput">
								</div>
								<div class="markdown">
									# And actually we only want only the "code"s that start with one of ABCDEFGHJKLMTXZ (Only these are valid categories) (why?)
								</div>
								<div class="codeinput">
									train = train[ train["code"].apply( lambda s: s[0] in "ABCDEFGHJKLMTXZ" ) ]
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								1: getting features
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									from numpy import isnan
									<br/>notnan = lambda x: not ( isinstance( x,float ) and isnan( x ) )
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									import re
									<br/>import string
									<br/>train["feature_occupationemployer"] = ( train["occupation"].apply( lambda s: s.strip() if notnan( s ) &nbsp;else "" )+" "+train["employer"].apply( lambda s: s.strip() if notnan( s ) &nbsp;else "" ) ).apply( lambda s: re.sub( "["+string.punctuation+"]","",s.strip() ) )
									<br/>train["feature_industryprefix"] = train["code"].apply( lambda s: s[0] )
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									train_x from train["feature_occupationemployer"]
								</div>
								<div class="codeinput">
									from sklearn.feature_extraction.text import CountVectorizer 
									<br/>ourvectorizer = CountVectorizer( ngram_range=( 1,2 ),stop_words='english',min_df=2,max_df=train.shape[0] ) 
									<br/>train_x = ourvectorizer.fit_transform( train["feature_occupationemployer"] ).toarray()
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									train_y from train["feature_industryprefix"]
								</div>
								<div class="codeinput">
									train_y = train["feature_industryprefix"]
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									test_x from test
								</div>
								<div class="codeinput">
									test_x = ourvectorizer.transform( test )
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									##### no `test_y`!
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								2: training our model
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									from sklearn.linear_model import LogisticRegression
									<br/>ourmodel = LogisticRegression().fit( train_x,train_y )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								3: testing our model
							</div>

							<div class="subchunk">
								<div class="markdown">
									"K" means "LAW" in this case. It also recognizes law firms ("SKADDEN ARPS")! The "F" category represents business and finance.
								</div>
								<div class="codeinput">
									print test
									<br/>print ourmodel.predict( test_x )
								</div>
								<div class="codeoutput">
									['LAWYER', 'SKADDEN ARPS', 'CEO']
									<br/>['K' 'K' 'F']
								</div>
								<div class="codeinput">
									for t,p in zip( test,ourmodel.predict( test_x ) ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print "======================================================================"
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print t
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print p,"(logistic regression)"
								</div>
								<div class="codeoutput">
									======================================================================
									<br/>LAWYER
									<br/>K (logistic regression)
									<br/>======================================================================
									<br/>SKADDEN ARPS
									<br/>K (logistic regression)
									<br/>======================================================================
									<br/>CEO
									<br/>F (logistic regression)
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								&bull; using `Pipeline`
								<br/>1: getting features
								<br/>2: training our model
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									from numpy import isnan
									<br/>notnan = lambda x: not ( isinstance( x,float ) and isnan( x ) )
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									import re
									<br/>import string
									<br/>train["feature_occupationemployer"] = ( train["occupation"].apply( lambda s: s.strip() if notnan( s ) &nbsp;else "" )+" "+train["employer"].apply( lambda s: s.strip() if notnan( s ) &nbsp;else "" ) ).apply( lambda s: re.sub( "["+string.punctuation+"]","",s.strip() ) )
									<br/>train["feature_industryprefix"] = train["code"].apply( lambda s: s[0] )
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									Build a simple machine learning pipeline to turn the above arrays into something scikit-learn understands
								</div>
								<div class="codeinput">
									from sklearn.pipeline import Pipeline
									<br/>from sklearn.feature_extraction.text import CountVectorizer
									<br/>from sklearn.linear_model import LogisticRegression
									<br/>ourpipeline = Pipeline( [
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;( 'vectorizer',CountVectorizer( ngram_range=( 1,2 ),stop_words='english',min_df=2,max_df=train.shape[0] ) ),
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;( 'classifier',LogisticRegression() )
									<br/>] )
									<br/>ourpipeline.fit( train["feature_occupationemployer"],train["feature_industryprefix"] )
								</div>
								<div class="codeoutput">
									<span class="pre">Pipeline(steps=[('vectorizer', CountVectorizer(analyzer=u'word', binary=False, charset=None,</span>
									<br/><span class="pre">        charset_error=None, decode_error=u'strict',</span>
									<br/><span class="pre">        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',</span>
									<br/><span class="pre">        lowercase=True, max_df=66915, max_features=None, min_df=2,</span>
									<br/><span class="pre">        ngram_range=(1, ...e, fit_intercept=True,</span>
									<br/><span class="pre">          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001))])</span>
								</div>
							</div>

							<div class="subchunktitle">
								3: testing our model
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									print test
									<br/>print ourpipeline.predict( test )
								</div>
								<div class="codeoutput">
									['LAWYER', 'SKADDEN ARPS', 'CEO']
									<br/>['K' 'K' 'F']
								</div>
								<div class="codeinput">
									for t,p in zip( test,ourpipeline.predict( test ) ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print "======================================================================"
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print t
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print p,"(logistic regression)"
								</div>
								<div class="codeoutput">
									======================================================================
									<br/>LAWYER
									<br/>K (logistic regression)
									<br/>======================================================================
									<br/>SKADDEN ARPS
									<br/>K (logistic regression)
									<br/>======================================================================
									<br/>CEO
									<br/>F (logistic regression)
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-exam" id="exam_wine_data">
						<div class="boxtitle">
							WINE DATA
						</div>
						<div class="markdown">
							import wine.csv and build a decision tree classifier to predict wine_cultivar. Test the data using 5-fold cross validation
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								0: loading &amp; exploring data
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/>df = pd.read_csv("wine.csv")
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									df.columns
								</div>
								<div class="codeoutput">
									<span class="pre">Index([u'wine_cultivar', u'Alcohol', u' Malic_acid', u' </span>Ash',
									<br/><span class="pre">       u' Alcalinity_of_ash', u' Magnesium', u' </span>Total_phenols', u' Flavanoids',
									<br/><span class="pre">       u' Nonflavanoid_phenols', u' Proanthocyanins', u' </span>Color_intensity',
									<br/><span class="pre">       u' Hue', u' OD280_OD315_of_diluted_wines', u' </span>Proline'],
									<br/><span class="pre">      dtype='object')</span>
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								1: getting features
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									full_x = df[[u'Alcohol', u' Malic_acid', u' Ash', u' Alcalinity_of_ash', u' Magnesium', u' Total_phenols', u' Flavanoids', u' Nonflavanoid_phenols', u' Proanthocyanins', u' Color_intensity', u' Hue', u' OD280_OD315_of_diluted_wines', u' Proline']]
									<br/>full_y = df['wine_cultivar']
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								2: training our model
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									from sklearn.tree import DecisionTreeClassifier
									<br/>ourmodel = DecisionTreeClassifier().fit( full_x,full_y )
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									from sklearn.cross_validation import cross_val_score
									<br/>scores = cross_val_score( ourmodel,full_x,full_y,cv=5 )
									<br/>scores.mean()
								</div>
								<div class="codeoutput">
									0.9326984126984128
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								3: testing our model
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-exam" id="exam_wine_data_knn">
						<div class="boxtitle">
							WINE DATA
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									Let's work with the wine dataset we worked with before, but slightly modified. This has more instances and different target features
									<br/>https://raw.githubusercontent.com/datapolitan/lede_algorithms/master/class5_2/data/wine.csv
									<br/>based on http://blog.yhathq.com/posts/classification-using-knn-and-python.html
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/>df = pd.read_csv( "wine copy.csv" )
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
								</div>
								<div class="codeinput">
									df.dtypes
								</div>
								<div class="codeoutput">
									<span class="pre">fixed_acidity           float64</span>
									<br/><span class="pre">volatile_acidity        float64</span>
									<br/><span class="pre">citric_acid             float64</span>
									<br/><span class="pre">residual_sugar          float64</span>
									<br/><span class="pre">chlorides               float64</span>
									<br/><span class="pre">free_sulfur_dioxide     float64</span>
									<br/><span class="pre">total_sulfur_dioxide    float64</span>
									<br/><span class="pre">density                 float64</span>
									<br/><span class="pre">pH                      float64</span>
									<br/><span class="pre">sulphates               float64</span>
									<br/><span class="pre">alcohol                 float64</span>
									<br/><span class="pre">quality                   int64</span>
									<br/><span class="pre">color                    object</span>
									<br/><span class="pre">is_red                  float64</span>
									<br/><span class="pre">high_quality            float64</span>
									<br/><span class="pre">dtype: object</span>
								</div>

								<div class="markdown">
									Instead of wine cultvar, we have the wine color (red or white), as well as a binary (is red) and high quality indicator (0 or 1)
								</div>
								<div class="codeinput">
									df["high_quality"].unique()
								</div>
								<div class="codeoutput">
									array([ 0.,  1.])
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
									from sklearn.cross_validation import train_test_split
									<br/>train_x,test_x,train_y,test_y = train_test_split( df[ [ 'density','sulphates','residual_sugar' ] ],df['high_quality'],train_size=0.75 )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
									from sklearn.neighbors import KNeighborsClassifier
									<br/>ourmodel = KNeighborsClassifier( n_neighbors=1 ).fit( train_x,train_y )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
									from sklearn import metrics 
									<br/>preds_from_test_x = ourmodel.predict( test_x )
									<br/>print metrics.accuracy_score( test_y,preds_from_test_x )
								</div>
								<div class="codeoutput">
									0.787692307692
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull; Not bad. Let's see what happens as the k changes
								</div>
								<div class="codeinput">
									from sklearn.neighbors import KNeighborsClassifier
									<br/>from sklearn import metrics
									<br/>results = []
									<br/>for k in range( 1,51,2 ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;ourmodel = KNeighborsClassifier( n_neighbors=k ).fit( train_x,train_y )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;preds_from_test_x = ourmodel.predict( test_x )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;results.append( [ k,metrics.accuracy_score( test_y,preds_from_test_x ) ] )
									<br/>
									<br/>results = pd.DataFrame( results,columns=[ "k","accuracy" ] )
									<br/>
									<br/>import matplotlib.pyplot as plt
									<br/>## %matplotlib inline
									<br/>plt.plot( results["k"],results["accuracy"] )
									<br/>plt.title( "Accuracy with Increasing K" )
									<br/>plt.show()
								</div>
								<div class="codeoutput">
								</div>
								<div class="markdown">
									# plateaus out # noise # Looks like about 80% is the best we can do. The way it plateaus suggests there's not much more to be gained by increasing k
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									# We can also tune this a bit by not weighting each instance the same, but decreasing the weight as the distance increases
									<br/># This actually increases the accuracy of our prediction
								</div>
								<div class="codeinput">
									from sklearn.neighbors import KNeighborsClassifier
									<br/>from sklearn import metrics
									<br/>results = []
									<br/>for k in range( 1,51,2 ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;ourmodel = KNeighborsClassifier( n_neighbors=k,weights='distance' ).fit( train_x,train_y )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;preds_from_test_x = ourmodel.predict( test_x )
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;results.append( [ k,metrics.accuracy_score( test_y,preds_from_test_x ) ] )
									<br/>
									<br/>results = pd.DataFrame( results,columns=[ "k","accuracy" ] )
									<br/>
									<br/>import matplotlib.pyplot as plt
									<br/>## %matplotlib inline
									<br/>plt.plot( results["k"],results["accuracy"] )
									<br/>plt.title( "Accuracy with Increasing K" )
									<br/>plt.show()
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-exam" id="exam_titanic_data">
						<div class="boxtitle">
							TITANIC DATA
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									0: loading &amp; exploring data
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/>titanic = pd.read_csv( "titanic.csv" )
								</div>

								<div class="markdown">
									explore
								</div>
								<div class="codeinput">
									titanic.columns
								</div>
								<div class="codeoutput">
									Index([u'row.names', u'pclass', u'survived', u'name', u'age', u'embarked',u'home.dest', u'room', u'ticket', u'boat', u'sex'],dtype='object')
								</div>
								<div class="markdown">
									count of missing values (NaN) in each column
								</div>
								<div class="codeinput">
									titanic.isnull().sum()
								</div>
								<div class="markdown">
									proportion of missing values (NaN) in each column
								</div>
								<div class="codeinput">
									titanic.isnull().sum() / titanic.shape[0]
								</div>
								<div class="codeoutput">
									0.5178979436405179
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									1: getting features
									<br/># Let's do a simple logistic regression to predict survival based on pclass and sex
								</div>
								<div class="codeinput">
									titanic = titanic.join( pd.get_dummies( titanic['pclass'],prefix="pclass" ) )
									<br/>titanic['sex_female'] = titanic['sex'].apply( lambda x: x == 'female' )
								</div>
								<div class="codeinput">
									train_x = titanic[ [ "pclass_2nd","pclass_3rd","sex_female" ] ]
									<br/>train_y = titanic["survived"]
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									2: fitting our model
									<br/># Remember we drop one value in each dummy to avoid the dummy variable trap
								</div>
								<div class="codeinput">
									from sklearn.linear_model import LogisticRegression
									<br/>lm = LogisticRegression().fit( train_x,train_y )
								</div>
								<div class="codeinput">
									from sklearn.naive_bayes import GaussianNB
									<br/>ourmodel_gaus = GaussianNB().fit( train_x,train_y )
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									3: 
								</div>
								<div class="codeinput">
									lm.score( titanic[ [ "pclass_2nd","pclass_3rd","sex_female" ] ],titanic["survived"] )
								</div>
								<div class="codeoutput">
								</div>
								<div class="codeinput">
									titanic["survived"].mean()
								</div>
								<div class="codeoutput">
								</div>
								<div class="codeinput">
									lm.coef_
								</div>
								<div class="codeoutput">
								</div>
								<div class="codeinput">
									lm.intercept_
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									# what if we dropeed "plass_3rd instead?"
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-exam" id="exam_bill_titles_data">
						<div class="boxtitle">
							BILL TITLES DATA
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								0: loading &amp; exploring data
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/>train = pd.read_csv( "bills_training.txt",sep="|",header=None,names=[ "title","category" ] )
								</div>
								<div class="codeinput">
									train[ train.isnull().any( axis=1 ) ]
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									# So it looks like the file is formatted strangely: Very long bill titles are broken up into several lines, so that the lines following the first start with 5 spaces ("&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;").
									<br/># To fix this formatting problem,
									<br/># we first read the file in with `open()`,
									<br/># fix the formatting,
									<br/># and then use `StringIO` and `pandas` to create a dataframe
								</div>
								<div class="codeinput">
									with open( "bills_training.txt","rU" ) as ourfile:
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;ourstring = ourfile.read().replace( "\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;","" )
									<br/>from StringIO import StringIO
									<br/>import pandas as pd
									<br/>train = pd.read_csv( StringIO( ourstring ),sep="|",header=None,names=[ "title","category" ] )
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
								</div>
								<div class="codeinput">
									train[ train.isnull().any( axis=1 ) ]
								</div>
								<div class="codeoutput">
									# is now an empty dataframe
								</div>

								<div class="markdown">
								</div>
								<div class="codeinput">
									train.head()
								</div>
								<div class="codeoutput">
									<span class="pre">                                               title              category</span>
									<br/><span class="pre">0  An act to amend Section 44277 of the Education...             Education</span>
									<br/><span class="pre">1  An act to add Section 8314.4 to the Government...       Public Services</span>
									<br/><span class="pre">2  An act to amend Sections 226, 233, and 234 of,...  Labor and Employment</span>
									<br/><span class="pre">3  An act to amend Sections 12920, 12921, 12926, ...  Labor and Employment</span>
									<br/><span class="pre">4  An act to amend Section 186.8 of, and to add S...                 Crime</span>
								</div>

								<div class="markdown">
									For our test data, we just
								</div>
								<div class="codeinput">
									test = [
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;"Public postsecondary education: executive officer compensation.",
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;"An act to add Section 236.3 to the Education code, related to the pricing of college textbooks.",
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;"Political Reform Act of 1974: campaign disclosures.",
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;"An act to add Section 236.3 to the Penal Code, relating to human trafficking.",
									<br/>]
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								1: getting features
							</div>

							<div class="subchunk">
								<div class="markdown">
									<span class="fullunderscore"><span class="temp">train_x</span></span> from <span class="fullunderscore"><span class="usermade">train</span>[<span class="usermade">"title"</span>]</span>
								</div>

								<div class="markdown">
									raw counts # stop_words='english'
								</div>
								<div class="codeinput">
									from sklearn.feature_extraction.text import CountVectorizer
									<br/>ourvectorizer = CountVectorizer()
									<br/><span class="temp">train_x</span> = ourvectorizer.fit_transform( <span class="usermade">train</span>[<span class="usermade">"title"</span>] ).toarray()
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									TF (normalized to unit vectors) # stop_words='english',
								</div>
								<div class="codeinput">
									from sklearn.feature_extraction.text import TfidfVectorizer
									<br/>ourvectorizer = TfidfVectorizer( use_idf=False )
									<br/><span class="temp">train_x</span> = ourvectorizer.fit_transform( <span class="usermade">train</span>[<span class="usermade">"title"</span>] ).toarray()
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									TFIDF (`sklearn` variant: first smooths counts so there are no 0's, smooth_idf : boolean, default=True) # stop_words='english',
								</div>
								<div class="codeinput">
									from sklearn.feature_extraction.text import TfidfVectorizer
									<br/>ourvectorizer = TfidfVectorizer()
									<br/><span class="temp">train_x</span> = ourvectorizer.fit_transform( <span class="usermade">train</span>[<span class="usermade">"title"</span>] ).toarray()
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									# improving 
									<br/>ourvectorizer = CountVectorizer( stop_words="english" ) # kinda sorta better?
									<br/>ourvectorizer = CountVectorizer( stop_words="english",ngram_range=( 1,2 ) )
									<br/>ourvectorizer = CountVectorizer( stop_words="english",min_df=2 ) # hmm reduces our accuracy but still within the margin of error
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									<span class="fullunderscore"><span class="temp">train_y</span></span> from <span class="fullunderscore"><span class="usermade">train</span>[<span class="usermade">"category"</span>]</span>
								</div>

								<div class="markdown">
									# `sklearn` models want our categories to be numbers NOT strings. The LabelEncoder performs this transformation.
								</div>
								<div class="codeinput">
									from sklearn.preprocessing import LabelEncoder
									<br/>ourlabelencoder = LabelEncoder()
									<br/>train_y = ourlabelencoder.fit_transform( <span class="usermade">train</span>[<span class="usermade">"category"</span>] )
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									# Later, we can transform them back using
								</div>
								<div class="codeinput aside">
									ourlabelencoder.classes_[ <span class="usermade">2</span> ]
								</div>
								<div class="codeinput aside">
									ourlabelencoder.inverse_transform( <span class="usermade">2</span> )
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									<span class="fullunderscore"><span class="temp">test_x</span></span> from <span class="fullunderscore"><span class="usermade">test</span></span>
									<br/># <span class="fullunderscore pre">.fit_transform()</span> for <span class="fullunderscore">train_x</span>
									<br/># <span class="fullunderscore pre">    .transform()</span> for <span class="fullunderscore">test_x</span>
								</div>
								<div class="codeinput">
									<span class="temp">test_x</span> = ourvectorizer.transform( <span class="usermade">test</span> ).toarray()
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									###### no <span class="fullunderscore"><span class="temp">test_y</span></span>! Just going with <span class="temp">test</span>
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									2: fitting our model
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									3: <strike>scoring, parameters</strike>, predicting, <strike>visualizing</strike>
								</div>
								<div class="codeinput">
									<span class="comment"># logistic regression</span>
									<br/><span class="comment"># decision tree</span>
									<br/><span class="comment"># multinomial naive bayes</span>
									<br/>for t,l,d,m in zip( test,ourmodel_logi.predict( test_x ),ourmodel_deci.predict( test_x ),ourmodel_mult.predict( test_x ) ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print "======================================================================"
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print t 
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print ourlabelencoder.classes_[l],"(logistic regression)" 
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print ourlabelencoder.classes_[d],"(decision tree)" 
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print ourlabelencoder.classes_[m],"(multinomial naive bayes)"
								</div>
								<div class="codeoutput">
									======================================================================
									<br/>Public postsecondary education: executive officer compensation.
									<br/>Education (logistic regression)
									<br/>Education (decision tree)
									<br/>Education (multinomial naive bayes)
									<br/>======================================================================
									<br/>An act to add Section 236.3 to the Education code, related to the pricing of college textbooks.
									<br/>Education (logistic regression)
									<br/>Education (decision tree)
									<br/>Education (multinomial naive bayes)
									<br/>======================================================================
									<br/>Political Reform Act of 1974: campaign disclosures.
									<br/>Campaign Finance and Election Issues (logistic regression)
									<br/>Campaign Finance and Election Issues (decision tree)
									<br/>Campaign Finance and Election Issues (multinomial naive bayes)
									<br/>======================================================================
									<br/>An act to add Section 236.3 to the Penal Code, relating to human trafficking.
									<br/>Crime (logistic regression)
									<br/>Crime (decision tree)
									<br/>Crime (multinomial naive bayes)
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-exam" id="exam_releases_data">
						<div class="boxtitle">
							RELEASES DATA
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								0: loading &amp; exploring data
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/>train = pd.read_csv( "releases_training.txt",sep="|",header=None,names=[ "title","drug-related" ] )
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									For our test data, we just
									<br/>the test data looks vastly different from the training data. okay?
								</div>
								<div class="codeinput">
									test = [
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;"Five Columbia Residents among 10 Defendants Indicted for Conspiracy to Distribute a Ton of Marijuana", 
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment"># Courtesy of Ms. Katie Worth:</span>
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;"13 convicted for their roles in a Montana drug trafficking operation run from a California prison",
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;"Career financial criminal deported, faces prison in Romania",
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;"Guatemalan living in east Texas pleads guilty to producing child pornography",
									<br/>]
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								1: getting features
							</div>

							<div class="subchunk">
								<div class="markdown">
									<span class="fullunderscore"><span class="temp">train_x</span></span> from <span class="fullunderscore"><span class="usermade">train</span>[<span class="usermade">"title"</span>]</span>
								</div>

								<div class="markdown">
									raw counts # stop_words='english'
								</div>
								<div class="codeinput">
									from sklearn.feature_extraction.text import CountVectorizer
									<br/>ourvectorizer = CountVectorizer()
									<br/><span class="temp">train_x</span> = ourvectorizer.fit_transform( <span class="usermade">train</span>[<span class="usermade">"title"</span>] ).toarray()
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									<span class="fullunderscore"><span class="temp">train_y</span></span> from <span class="fullunderscore"><span class="usermade">train</span>[<span class="usermade">"drug-related"</span>]</span>
								</div>
								<div class="codeinput">
									train_y = <span class="usermade">train</span>[<span class="usermade">"drug-related"</span>]
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									<span class="fullunderscore"><span class="temp">test_x</span></span> from <span class="fullunderscore"><span class="usermade">test</span></span>
								</div>
								<div class="codeinput">
									<span class="temp">test_x</span> = ourvectorizer.transform( <span class="usermade">test</span> ).toarray()
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									###### no <span class="fullunderscore"><span class="temp">test_y</span></span>! Just going with <span class="temp">test</span>
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								2: training our model
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									from sklearn.naive_bayes import MultinomialNB
									<br/>ourmodel_mult = MultinomialNB().fit( train_x,train_y )
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunktitle">
								3: testing our model
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									for t,m in zip( test,ourmodel_mult.predict( test_x ) ):
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print "======================================================================"
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print t
									<br/>&nbsp;&nbsp;&nbsp;&nbsp;print m,"(multinomial naive bayes)"
								</div>
								<div class="codeoutput">
									======================================================================
									<br/>Five Columbia Residents among 10 Defendants Indicted for Conspiracy to Distribute a Ton of Marijuana
									<br/>YES (multinomial naive bayes)
									<br/>======================================================================
									<br/>13 convicted for their roles in a Montana drug trafficking operation run from a California prison
									<br/>YES (multinomial naive bayes)
									<br/>======================================================================
									<br/>Career financial criminal deported, faces prison in Romania
									<br/>YES (multinomial naive bayes)
									<br/>======================================================================
									<br/>Guatemalan living in east Texas pleads guilty to producing child pornography
									<br/>YES (multinomial naive bayes)
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-defi" id="defi_clustering">
						<div class="boxtitle">
							CLUSTERING
						</div>
						<div class="markdown">
							# the intuition and dangers of UNsupervised learning, also known as clustering
							<br/>
							<br/># Rather than train a model based on pre-determined categories,
							<br/># clusters the data along natural borders
						</div>
					</div>

					<div class="boxcontent box-code" id="code_kmeans">
						<div class="boxtitle">
							K MEANS
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-code" id="code_dbscan">
						<div class="boxtitle">
							DBSCAN
						</div>
						<div class="markdown">
							DBSCAN is a density-based clustering algorithm that finds points based on their proximity to other points in the dataset. Unlike algorithms such as K-means, you do not need to specify 
							<br/>the number of clusters you would like it to find in advance. Instead, you set 
							<br/>epsilon, a parameter that identifies how close you would like two points to be for them to belong to the same cluster.
							<br/>
							<br/>http://en.wikipedia.org/wiki/DBSCAN
							<br/>http://scikit-learn.org/dev/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN
							<br/>And there's a clean, documented implementation here for reference:
							<br/>https://github.com/cjdd3b/car-datascience-toolkit/blob/master/cluster/dbscan.py
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-exam" id="exam_congressional_speeches_data">
						<div class="boxtitle">
							CONGRESSIONAL SPEECHES DATA
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									We'll be using data from http://www.cs.cornell.edu/home/llee/data/convote.html to explore k-means clustering
									<br/>link that says "convote dataset v1.1 (9.8 Mb, tar.gz format)"
									<br/>
								</div>
								<div class="codeinput">

								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-exam" id="exam_columbia_mo_crime_data">
						<div class="boxtitle">
							COLUMBIA MO CRIME DATA
						</div>

						<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									demonstrates the use of the DBSCAN algorithm for finding clusters of crimes in Columbia, Mo.
								</div>
								<div class="codeinput">
									import pandas as pd
									<br/>df = pd.read_csv( "columbia_crime.csv" )
								</div>
								<div class="codeinput">
									df.head()
								</div>
								<div class="codeoutput">
									<span class="pre">        InNum ProQANumber   CallDateTime   Timestamp  \</span>
									<br/><span class="pre">0  2015143105      P41645  8/10/15 23:58  1439269114   </span>
									<br/><span class="pre">1  2015143100      P41644  8/10/15 23:37  1439267845   </span>
									<br/><span class="pre">2  2015143096         NaN  8/10/15 23:34  1439267666   </span>
									<br/><span class="pre">3  2015143095         NaN  8/10/15 23:31  1439267511   </span>
									<br/><span class="pre">4  2015143092      P41642  8/10/15 23:23  1439267031   </span>
									<br/>
									<br/><span class="pre">                                Address AptLot       lng       lat GridLoc  \</span>
									<br/><span class="pre">0  PROVIDENCE RD S-CO/STADIUM BLVD E-CO    NaN -92.33430  38.93790  28134A   </span>
									<br/><span class="pre">1           TENTH ST N-CO/BROADWAY E-CO    NaN -92.32650  38.95150  28124Q   </span>
									<br/><span class="pre">2                 800 STADIUM BLVD W-CO    NaN -92.35111  38.93819  28144A   </span>
									<br/><span class="pre">3                  900 RANGE LINE ST-CO    NaN -92.32459  38.96017  28122Q   </span>
									<br/><span class="pre">4                4113 DERBY RIDGE DR-CO    NaN -92.31791  38.99221  24311A   </span>
									<br/>
									<br/><span class="pre">   Disp  PDids ExtNatureDisplayName Report PolArea     DOW  HourNum  </span>
									<br/><span class="pre">0     2    200              TRAFFIC    NaN     60E  Monday       23  </span>
									<br/><span class="pre">1     9    200                  DWI    NaN     70D  Monday       23  </span>
									<br/><span class="pre">2     2    200        CHECK SUBJECT    NaN    50WP  Monday       23  </span>
									<br/><span class="pre">3     2    200         TRAFFIC STOP    NaN     20E  Monday       23  </span>
									<br/><span class="pre">4     2    200          TRESPASSING    NaN     30S  Monday       23  </span>
								</div>
								<div class="codeinput">
									df.shape
								</div>
								<div class="codeoutput">
									(1998, 16)
								</div>
								<div class="codeinput">
									df.dtypes
								</div>
								<div class="codeoutput">
									<span class="pre">InNum                     int64</span>
									<br/><span class="pre">ProQANumber              object</span>
									<br/><span class="pre">CallDateTime             object</span>
									<br/><span class="pre">Timestamp                 int64</span>
									<br/><span class="pre">Address                  object</span>
									<br/><span class="pre">AptLot                   object</span>
									<br/><span class="pre">lng                     float64</span>
									<br/><span class="pre">lat                     float64</span>
									<br/><span class="pre">GridLoc                  object</span>
									<br/><span class="pre">Disp                      int64</span>
									<br/><span class="pre">PDids                     int64</span>
									<br/><span class="pre">ExtNatureDisplayName     object</span>
									<br/><span class="pre">Report                   object</span>
									<br/><span class="pre">PolArea                  object</span>
									<br/><span class="pre">DOW                      object</span>
									<br/><span class="pre">HourNum                   int64</span>
									<br/><span class="pre">dtype: object</span>
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									We want proximities based on latitude and longitude, so check if any rows have missing "lat" "lng" entries
								</div>
								<div class="codeinput">
									df[ df["lat"].isnull() | df["lng"].isnull() ]
								</div>
								<div class="codeoutput">
									<span class="pre">          InNum ProQANumber  CallDateTime   Timestamp  \</span>
									<br/><span class="pre">779  2015140992         NaN  8/7/15 13:42  1438972955   </span>
									<br/><span class="pre">793  2015141007         NaN  8/7/15 12:55  1438970135   </span>
									<br/><span class="pre">854  2015140812         NaN   8/7/15 8:29  1438954184   </span>
									<br/>
									<br/><span class="pre">                              Address AptLot  lng  lat GridLoc  Disp  PDids  \</span>
									<br/><span class="pre">779  1565 OLD HAWTHORNE DRIVE EAST-CO    NaN  NaN  NaN  29231B     2    200   </span>
									<br/><span class="pre">793              430 BLK BAILEY DR-CO    NaN  NaN  NaN  28352A     2    200   </span>
									<br/><span class="pre">854           2300 BLK LONGWOOD DR-CO    NaN  NaN  NaN  33101B     2    200   </span>
									<br/>
									<br/><span class="pre">    ExtNatureDisplayName Report PolArea     DOW  HourNum  </span>
									<br/><span class="pre">779           911 CHECKS    NaN     80N  Friday       13  </span>
									<br/><span class="pre">793           911 CHECKS    NaN     60W  Friday       12  </span>
									<br/><span class="pre">854           911 CHECKS    NaN     60W  Friday        8  </span>
								</div>

								<div class="markdown">
									We get rid of these rows
								</div>
								<div class="codeinput">
									df = df[ df["lat"].notnull() &amp; df["lng"].notnull() ]
								</div>
								<div class="codeoutput">
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									# Scikit-learn's implemenetation of DBSCAN requires the input of
									<br/># a distance matrix showing pairwise distances between all points in the dataset.
									<br/># Run DBSCAN.
									<br/># Setting epsilon with lat/lon data like we have here is an inexact science. 0.03 looked good after a few test runs. Ideally we'd project the data and set epsilon using meters or feet.
								</div>
								<div class="codeinput">
									from scipy.spatial import distance
									<br/>ourdistancemetric = distance.squareform( distance.pdist( df[ [ "lat","lng" ] ] ) )
									<br/>from sklearn.cluster import DBSCAN
									<br/>ourclusters = DBSCAN( eps=0.03 ).fit( ourdistancemetric )
								</div>
								<div class="codeoutput">
								</div>
								
								<div class="markdown">
									`ourdistancemetric` is a (1995, 1995) numpy array &nbsp;of pairwise distances between all points in the dataset
								</div>
								<div class="codeinput aside">
									distance.squareform( distance.pdist( df[ [ "lat","lng" ] ] ) )
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
								</div>
								<div class="codeinput">
									df["dblabels"] = ourclusters.labels_
									<br/>df[ [ "dblabels",'ExtNatureDisplayName','lat','lng' ] ].sort( "dblabels" )
								</div>

								<div class="markdown">
									`ourclusters.labels_` a (1995,) numpy array &nbsp;of cluster numbers
								</div>
								<div class="codeinput aside">
									ourclusters.labels_
								</div>
								<div class="codeoutput">
								</div>

								<div class="markdown">
									You can save this to a file and import directly into a mapping program or Fusion Tables if you want to visualize it. Google My Maps
								</div>
								<div class="codeinput">
									df[ [ "dblabels",'ExtNatureDisplayName','lat','lng' ] ].sort( "dblabels" ).to_csv( "columbia_crime_clustered.csv",index=False )
								</div>
							</div>

							<div class="subchunk">
								<div class="markdown">
									take a look at [this map](https://www.google.com/maps/d/u/1/embed?mid=z9S6reOYqCIE.kQnlzV2-uDzg), which 
									<br/>shows police dispatch logs for Columbia, Mo., over the first 10 days of August.
									<br/>Within the map, there are three layers (eps_0.3, eps_0.2, eps_0.4), each of which shows hotspots of dispatches calculated in slightly different ways. Choose what you think is the fairest representations of the hotsports and write a couple paragraphs characterizing your findings.
								</div>
							</div>
						</div>
					</div>

					<div class="boxcontent box-" id="_little_tips">
						<div class="boxtitle">
							little tips
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
									# To avoid confusion,
									# save data set files in your Lede folder;
									# in terminal move to the Lede folder
									# before firing up iPython notebook or running python;
									# then in the same Lede folder create a new iPython notebook or a Python script file

									<br/>
									# View > Show Path Bar
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
									# Fix .ipynb saving as .ipynb.txt
									# Windows: Go to View > ??? > UNclick Hide extension
									# Mac: Right click on the file,
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>

		 				<div class="chunk">
							<div class="subchunk">
								<div class="markdown">
									&bull;
									# if the * won't go away and you've lost your computer
									# Kernel > Interrupt
								</div>
								<div class="codeinput">
								</div>
								<div class="codeoutput">
								</div>
							</div>
						</div>
					</div>

				<!-- boxstructure -->
					<div class="boxstructure_wrapper">
					</div>
					<script>
						var boxes_hiddleston_arra = [
							//
							{
								"boxtype":"note",
								"content_small":"little tips",
								"content_id":"_little_tips"
							},
							//
							//
							//
							//
							{
								"boxtype":"code",
								"content_small":"Installing &amp; importing pandas",
								"content_id":"code_installing_importing"
							},
							//
							{
								"boxtype":"none boxesheader",
								"content_small":"Creating a DataFrame...",
								"content_id":"none_creating_dataframe"
							},
							{
								"boxtype":"code",
								"content_small":"...from other data structures",
								"content_id":"code_from_other_data_structures"
							},
							{
								"boxtype":"code",
								"content_small":"...by reading a file",
								"content_id":"code_reading_file"
							},
							{
								"boxtype":"exam",
								"content_small":"seeds data",
								"content_id":"exam_reading_seeds_file"
							},
						];
						var boxes_hemsworth_arra = [
							//
							{
								"boxtype":"none boxesheader",
								"content_small":"Checking basic properties like...",
								"content_id":"none_"
							},
							{
								"boxtype":"code",
								"content_small":"...number of rows &amp; columns, <br/>data types, <br/>row index names &amp; column names <br/>number of missing values <br/>unique values",
								"content_id":"code_checking_basic_properties"
							},
							//
							{
								"boxtype":"none",
								"content_small":"Selecting rows &amp; columns...",
								"content_id":"_"
							},
							{
								"boxtype":"code",
								"content_small":"...by position or name",
								"content_id":"code_selecting_by_position_or_name"
							},
							{
								"boxtype":"code",
								"content_small":"...that meet conditions",
								"content_id":"code_selecting_by_condition"
							},
							{
								"boxtype":"exam",
								"content_small":"film ratings data",
								"content_id":"_"
							},
							{
								"boxtype":"code",
								"content_small":"groupby",
								"content_id":"_"
							},
							{
								"boxtype":"code",
								"content_small":"merge",
								"content_id":"_"
							},
							//
							{
								"boxtype":"none",
								"content_small":"Visualizing",
								"content_id":"none_"
							},
							{
								"boxtype":"code",
								"content_small":"",
								"content_id":"_"
							},
							//
							{
								"boxtype":"none",
								"content_small":"descriptive statistics",
								"content_id":"_"
							},
							{
								"boxtype":"code",
								"content_small":"",
								"content_id":"_"
							},
							{
								"boxtype":"code",
								"content_small":"",
								"content_id":"_"
							},
						];
						var boxes_evans_arra = [
							//
							{
								"boxtype":"none",
								"content_small":"0: loading &amp; exploring data",
								"content_id":"_"
							},
							//
							{
								"boxtype":"none",
								"content_small":"1: getting features <br/>feature engineering <br/>feature space <br/>curse of dimensionality <br/>dimensionality reduction",
								"content_id":"_"
							},
							{
								"boxtype":"none",
								"content_small":"for a categorical variable,",
								"content_id":"_"
							},
							{
								"boxtype":"code",
								"content_small":"dummy variables",
								"content_id":"_"
							},
							{
								"boxtype":"none",
								"content_small":"for a text document,",
								"content_id":"_"
							},
							{
								"boxtype":"code",
								"content_small":"vectorization",
								"content_id":"code_vectorization"
							},
							{
								"boxtype":"code",
								"content_small":"sentence segmentation",
								"content_id":"code_sentence_segmentation"
							},
							{
								"boxtype":"code",
								"content_small":"removing punctuation",
								"content_id":"code_removing_punctuation_from_string"
							},
							//
							{
								"boxtype":"none",
								"content_small":"2: training our model",
								"content_id":"_"
							},
							//
							{
								"boxtype":"none",
								"content_small":"3: testing our model",
								"content_id":"_"
							},
							{
								"boxtype":"code",
								"content_small":"cross validation",
								"content_id":"code_cross_validation"
							},
							{
								"boxtype":"code",
								"content_small":"hold out sets",
								"content_id":"code_hold_out"
							},
							{
								"boxtype":"none",
								"content_small":"scoring (R-score,a/p/r/f1/matrix) <br/>parameters <br/>predicting <br/>visualizing",
								"content_id":"_"
							},
							{
								"boxtype":"defi",
								"content_small":"scoring stuff",
								"content_id":"defi_scoring_stuff"
							},
						];
						var boxes_johansson_arra = [
							//
							{
								"boxtype":"defi",
								"content_small":"regression",
								"content_id":"defi_regression"
							},
							{
								"boxtype":"algo",
								"content_small":"linear regression",
								"content_id":"code_linear_regression"
							},
							{
								"boxtype":"algo",
								"content_small":"polynomial regression",
								"content_id":"code_polynomial_regression"
							},
							{
								"boxtype":"exam",
								"content_small":"height weight data",
								"content_id":""
							},
							{
								"boxtype":"exam",
								"content_small":"flight data",
								"content_id":""
							},
							{
								"boxtype":"exam",
								"content_small":"schools data",
								"content_id":""
							},
							{
								"boxtype":"exam",
								"content_small":"hanford data",
								"content_id":""
							},
						];
						var boxes_downeyjr_arra = [
							//
							{
								"boxtype":"defi",
								"content_small":"classification",
								"content_id":"defi_classification"
							},
							{
								"boxtype":"algo",
								"content_small":"logistic regression",
								"content_id":"code_logistic_regression"
							},
							{
								"boxtype":"algo",
								"content_small":"decision tree",
								"content_id":"code_decision_tree"
							},
							{
								"boxtype":"algo",
								"content_small":"naive Bayes",
								"content_id":"code_naive_bayes"
							},
							{
								"boxtype":"none",
								"content_small":"random forest",
								"content_id":"code_random_forest"
							},
							{
								"boxtype":"none",
								"content_small":"support vector machine",
								"content_id":"code_support_vector_machine"
							},
							{
								"boxtype":"algo",
								"content_small":"k nearest neighbors",
								"content_id":"code_knn"
							},
							{
								"boxtype":"exam",
								"content_small":"iris data",
								"content_id":"exam_iris_data"
							},
							{
								"boxtype":"exam",
								"content_small":"seeds data",
								"content_id":"exam_seeds_data"
							},
							{
								"boxtype":"exam",
								"content_small":"donor names data",
								"content_id":"exam_donor_names_data"
							},
							{
								"boxtype":"exam",
								"content_small":"donor occupations data",
								"content_id":"exam_donor_occupations_data"
							},
							{
								"boxtype":"exam",
								"content_small":"wine data",
								"content_id":"exam_wine_data"
							},
							{
								"boxtype":"exam",
								"content_small":"wine data",
								"content_id":"exam_wine_data_knn"
							},
							{
								"boxtype":"exam",
								"content_small":"titanic data",
								"content_id":"exam_titanic_data"
							},
							{
								"boxtype":"exam",
								"content_small":"bill titles data",
								"content_id":"exam_bill_titles_data"
							},
							{
								"boxtype":"exam",
								"content_small":"releases data",
								"content_id":"exam_releases_data"
							},
						];
						var boxes_ruffalo_arra = [
							//
							{
								"boxtype":"defi",
								"content_small":"clustering",
								"content_id":"defi_clustering"
							},
							{
								"boxtype":"algo",
								"content_small":"k means",
								"content_id":"code_kmeans"
							},
							{
								"boxtype":"algo",
								"content_small":"dbscan",
								"content_id":"code_dbscan"
							},
							{
								"boxtype":"exam",
								"content_small":"congressional speeches data",
								"content_id":"exam_congressional_speeches_data"
							},
							{
								"boxtype":"exam",
								"content_small":"Columbia, MO crime data",
								"content_id":"exam_columbia_mo_crime_data"
							},
						];
						boxfiller( "lede",[ "hiddleston","hemsworth","evans","johansson","downeyjr","ruffalo", ] );
					</script>
			</div>
		</div>
	</div>
</BODY>
</HTML>